{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Training and Testing\n",
        "After data preprocessing, I aim to develop a 2 layer LSTM architecture which takes in a sequence of 30 cycles to predict the RUL of the engine. The whole process includes various steps :\n",
        "- The first step is of course, is to define the input to be fed. We will be feeding a 3D matrix to this network. We can visualize it by imagining a 30 x 14 dimension planes stacked over one another.\n",
        "- After the input matrix has been made then decide the loss function and the number of units in each layer. This is done by hyperparameter tuning. Note that, here we have used a custom asymmetric function to penalize late predictions more. Along with our custom loss function we are also keeping track of the loss function suggested by NASA and MSE.\n",
        "- The reason of not using NASA's suggested loss function is the fact that it contains exponential terms, and hence will cause exploding gradients.\n",
        "- After hyperparameter tuning model, we train and test the data"
      ],
      "metadata": {
        "id": "T91mdTTWXbO4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "yZ0D6osIz70A"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import mean_squared_error"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creation of Input Matrix"
      ],
      "metadata": {
        "id": "PHgOTTKeb0H5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_lstm_dataset(df, seq_length, feature_cols, target_cols = 'RUL'):\n",
        "  X_seq = []\n",
        "  Y_seq = []\n",
        "\n",
        "  for engine_id in df['unit_nr'].unique() :\n",
        "    engine_data = df[df['unit_nr'] == engine_id]\n",
        "    engine_array = engine_data[feature_cols].values #2d matrix\n",
        "    engine_rul = engine_data[target_cols].values\n",
        "    num_rows = engine_array.shape[0]\n",
        "    if num_rows < seq_length :\n",
        "      print('Enough data not available')\n",
        "      continue\n",
        "\n",
        "    for i in range(num_rows - seq_length + 1):\n",
        "      window = engine_array[i : i+seq_length]\n",
        "      target = engine_rul[i + seq_length -1]\n",
        "      X_seq.append(window)\n",
        "      Y_seq.append(target)\n",
        "\n",
        "  return np.array(X_seq), np.array(Y_seq)"
      ],
      "metadata": {
        "id": "klsQjfRa1NC7"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sliding Window to define output and input\n",
        "train_df = pd.read_csv('final_train_FD001.csv')\n",
        "feature_cols = ['s_2', 's_3', 's_4', 's_7', 's_8', 's_9', 's_11', 's_12', 's_13', 's_14', 's_15', 's_17', 's_20', 's_21' ]\n",
        "sequence_length = 30\n",
        "X_train, Y_train = create_lstm_dataset(train_df, sequence_length, feature_cols)\n",
        "print(X_train.shape)\n",
        "print(Y_train.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U10oOJRRym_V",
        "outputId": "493d1d24-9ae9-44ad-ac88-72be3b9588f3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(17731, 30, 14)\n",
            "(17731,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Defining Losses and LSTM"
      ],
      "metadata": {
        "id": "ANFbUkMYb6kh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom loss function to penalize late predictions more\n",
        "def NASA_loss(y_true, y_pred):\n",
        "  y_true = tf.cast(y_true, tf.float32)\n",
        "  d = y_pred - y_true\n",
        "  score_early = tf.math.exp(-d / 13.0) - 1\n",
        "  score_late = tf.math.exp(d / 10.0) - 1\n",
        "  loss_vector = tf.where(d < 0, score_early, score_late)\n",
        "  return K.mean(loss_vector)\n",
        "\n",
        "def safe_loss(alpha):\n",
        "  def _safe_loss(y_true, y_pred):\n",
        "    err = y_pred - y_true\n",
        "    alpha_f = tf.cast(alpha, tf.float32)\n",
        "    penalty_weight = tf.where(err > 0, alpha_f, 1.0)\n",
        "    return K.mean(penalty_weight * K.square(err))\n",
        "  return _safe_loss\n",
        "\n",
        "# Building LSTM\n",
        "def build_lstm_model(input_shape, layer1_units, layer2_units, dropout_rate, alpha) :\n",
        "  model = Sequential()\n",
        "  #  Layer 1 :\n",
        "  model.add(LSTM(units = layer1_units, input_shape = input_shape, return_sequences = True))\n",
        "  model.add(Dropout(dropout_rate))\n",
        "\n",
        "  # Layer 2 :\n",
        "  model.add(LSTM(units = layer2_units, return_sequences = False))\n",
        "  model.add(Dropout(dropout_rate))\n",
        "\n",
        "  # Output Layer : Regression\n",
        "  model.add(Dense(units = 1, activation = 'linear'))\n",
        "\n",
        "  model.compile(optimizer = 'adam', loss= safe_loss(alpha = alpha), metrics=['mse', NASA_loss])\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "1eZtfAODaWH-"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "M24Nw4aDbpXP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = (X_train.shape[1], X_train.shape[2]) #(30,14)\n",
        "# layer1_options = [50, 100, 150]\n",
        "# layer2_options = [64, 128, 256]\n",
        "layer1_options = [50,100,150]\n",
        "layer2_options = [32,64,128,256,512]\n",
        "alpha_options= [2,5,10,20,40,60,80,100]\n",
        "\n",
        "best_loss = float('inf')\n",
        "best_config = (100, 50,20) # Default placeholder\n",
        "\n",
        "print(f\"Starting Grid Search on {len(layer1_options) * len(layer2_options) * len(alpha_options)} combinations...\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "for u1 in layer1_options:\n",
        "    for u2 in layer2_options:\n",
        "      for alpha in alpha_options:\n",
        "        print(f\"Testing: Layer1={u1} -> Layer2={u2} ... -> Alpha = {alpha}\", end=\"\")\n",
        "        model = build_lstm_model(input_shape, u1, u2, 0.2, alpha)\n",
        "        history = model.fit(X_train, Y_train, epochs=5, batch_size=200, validation_split=0.2, verbose=1)\n",
        "        val_loss = history.history['val_loss'][-1]\n",
        "        val_mse_loss = history.history['val_mse'][-1]\n",
        "        val_NASA_loss = history.history['val_nasa_loss'][-1]\n",
        "        print(f\"Val asymm loss: {val_loss:.4f}\")\n",
        "        print(f\"Val NASA loss : {val_NASA_loss:.4f}\")\n",
        "        print(f\"Val mse loss : {val_mse_loss:.4f}\")\n",
        "\n",
        "\n",
        "        if val_loss < best_loss:\n",
        "            best_loss = val_loss\n",
        "            best_config = (u1, u2, alpha)\n",
        "\n",
        "\n",
        "print(f\" Final structure : Layer 1 = {best_config[0]}, Layer 2 = {best_config[1]}, alpha = {best_config[2]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43jq3AgirqfV",
        "outputId": "fbda9cd6-840d-4608-895d-0ec9d3ea30ab"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting Grid Search on 120 combinations...\n",
            "============================================================\n",
            "Testing: Layer1=50 -> Layer2=32 ... Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 7556.8423 - mse: 7556.6289 - nasa_loss: 4219.5483 - val_loss: 7500.1777 - val_mse: 7498.8696 - val_nasa_loss: 3272.3518\n",
            "Epoch 2/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 6754.6226 - mse: 6752.7393 - nasa_loss: 2636.2852 - val_loss: 7094.8447 - val_mse: 7091.9429 - val_nasa_loss: 2650.4014\n",
            "Epoch 3/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 6306.7412 - mse: 6303.0522 - nasa_loss: 2113.2410 - val_loss: 6750.5112 - val_mse: 6745.4282 - val_nasa_loss: 2200.6248\n",
            "Epoch 4/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 6118.9497 - mse: 6113.0293 - nasa_loss: 1825.6581 - val_loss: 6417.1704 - val_mse: 6408.9980 - val_nasa_loss: 1825.5278\n",
            "Epoch 5/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 5790.0693 - mse: 5780.3667 - nasa_loss: 1506.7744 - val_loss: 6110.4966 - val_mse: 6098.3936 - val_nasa_loss: 1526.8730\n",
            "Val asymm loss: 6110.4966\n",
            "Val NASA loss : 1526.8730\n",
            "Val mse loss : 6098.3936\n",
            "Testing: Layer1=50 -> Layer2=32 ... Epoch 1/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 7666.4521 - mse: 7665.8462 - nasa_loss: 4396.8887 - val_loss: 7599.1533 - val_mse: 7594.9468 - val_nasa_loss: 3435.5256\n",
            "Epoch 2/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 6809.4902 - mse: 6803.4976 - nasa_loss: 2740.3582 - val_loss: 7178.5322 - val_mse: 7168.4087 - val_nasa_loss: 2759.1492\n",
            "Epoch 3/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 6399.0518 - mse: 6385.6377 - nasa_loss: 2206.0486 - val_loss: 6829.1514 - val_mse: 6810.7388 - val_nasa_loss: 2280.2310\n",
            "Epoch 4/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 6114.7661 - mse: 6091.4883 - nasa_loss: 1846.3486 - val_loss: 6515.0063 - val_mse: 6485.5156 - val_nasa_loss: 1905.8951\n",
            "Epoch 5/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 5818.5503 - mse: 5784.0342 - nasa_loss: 1542.8285 - val_loss: 6228.3081 - val_mse: 6184.7368 - val_nasa_loss: 1605.6179\n",
            "Val asymm loss: 6228.3081\n",
            "Val NASA loss : 1605.6179\n",
            "Val mse loss : 6184.7368\n",
            "Testing: Layer1=50 -> Layer2=32 ... Epoch 1/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 7607.2280 - mse: 7604.4819 - nasa_loss: 4137.1582 - val_loss: 7362.5620 - val_mse: 7346.3457 - val_nasa_loss: 3026.4854\n",
            "Epoch 2/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 6513.4712 - mse: 6490.8569 - nasa_loss: 2377.7058 - val_loss: 6981.8613 - val_mse: 6948.5835 - val_nasa_loss: 2455.9871\n",
            "Epoch 3/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 6186.0977 - mse: 6144.1401 - nasa_loss: 1944.7384 - val_loss: 6671.6938 - val_mse: 6616.4150 - val_nasa_loss: 2050.0225\n",
            "Epoch 4/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 6007.4341 - mse: 5939.6704 - nasa_loss: 1671.8641 - val_loss: 6380.4888 - val_mse: 6295.1729 - val_nasa_loss: 1711.0652\n",
            "Epoch 5/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 5758.9785 - mse: 5657.4673 - nasa_loss: 1416.8108 - val_loss: 6128.3003 - val_mse: 6006.8135 - val_nasa_loss: 1446.7699\n",
            "Val asymm loss: 6128.3003\n",
            "Val NASA loss : 1446.7699\n",
            "Val mse loss : 6006.8135\n",
            "Testing: Layer1=50 -> Layer2=32 ... Epoch 1/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 7580.1187 - mse: 7575.0674 - nasa_loss: 4209.3452 - val_loss: 7364.6636 - val_mse: 7329.2378 - val_nasa_loss: 2999.8938\n",
            "Epoch 2/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 6579.2046 - mse: 6532.0264 - nasa_loss: 2375.8254 - val_loss: 6993.0103 - val_mse: 6919.3291 - val_nasa_loss: 2417.7891\n",
            "Epoch 3/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 6275.2964 - mse: 6187.9585 - nasa_loss: 1949.7040 - val_loss: 6710.3198 - val_mse: 6588.9766 - val_nasa_loss: 2019.0999\n",
            "Epoch 4/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 6033.1157 - mse: 5887.7905 - nasa_loss: 1650.1421 - val_loss: 6479.4619 - val_mse: 6300.5942 - val_nasa_loss: 1716.3823\n",
            "Epoch 5/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 5760.0400 - mse: 5559.3794 - nasa_loss: 1384.3793 - val_loss: 6289.8564 - val_mse: 6044.5752 - val_nasa_loss: 1479.3806\n",
            "Val asymm loss: 6289.8564\n",
            "Val NASA loss : 1479.3806\n",
            "Val mse loss : 6044.5752\n",
            "Testing: Layer1=50 -> Layer2=32 ... Epoch 1/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - loss: 7617.9502 - mse: 7610.1045 - nasa_loss: 4232.1299 - val_loss: 7579.3086 - val_mse: 7531.9263 - val_nasa_loss: 3327.7681\n",
            "Epoch 2/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 6845.2656 - mse: 6779.6631 - nasa_loss: 2686.1233 - val_loss: 7245.1587 - val_mse: 7141.5527 - val_nasa_loss: 2720.5488\n",
            "Epoch 3/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 6510.1787 - mse: 6375.5977 - nasa_loss: 2203.8130 - val_loss: 6996.3140 - val_mse: 6819.1045 - val_nasa_loss: 2290.5994\n",
            "Epoch 4/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 6259.6426 - mse: 6050.5020 - nasa_loss: 1841.1917 - val_loss: 6812.9146 - val_mse: 6549.7437 - val_nasa_loss: 1975.5502\n",
            "Epoch 5/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 6149.4189 - mse: 5839.0103 - nasa_loss: 1606.7911 - val_loss: 6680.9883 - val_mse: 6325.3662 - val_nasa_loss: 1740.8485\n",
            "Val asymm loss: 6680.9883\n",
            "Val NASA loss : 1740.8485\n",
            "Val mse loss : 6325.3662\n",
            "Testing: Layer1=50 -> Layer2=32 ... Epoch 1/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 7568.1636 - mse: 7549.1201 - nasa_loss: 4145.5596 - val_loss: 7410.2114 - val_mse: 7291.8223 - val_nasa_loss: 2942.3955\n",
            "Epoch 2/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 6632.6538 - mse: 6476.5532 - nasa_loss: 2335.8777 - val_loss: 7148.7163 - val_mse: 6920.3179 - val_nasa_loss: 2419.0867\n",
            "Epoch 3/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 6452.2480 - mse: 6175.9375 - nasa_loss: 1969.6970 - val_loss: 7000.4927 - val_mse: 6663.9380 - val_nasa_loss: 2105.0994\n",
            "Epoch 4/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 6323.7095 - mse: 5926.2236 - nasa_loss: 1716.1881 - val_loss: 6883.9844 - val_mse: 6490.0405 - val_nasa_loss: 1920.8859\n",
            "Epoch 5/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 6240.8359 - mse: 5864.6133 - nasa_loss: 1639.6871 - val_loss: 6337.1270 - val_mse: 6259.5488 - val_nasa_loss: 2004.0742\n",
            "Val asymm loss: 6337.1270\n",
            "Val NASA loss : 2004.0742\n",
            "Val mse loss : 6259.5488\n",
            "Testing: Layer1=50 -> Layer2=32 ... Epoch 1/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 7712.3369 - mse: 7703.6313 - nasa_loss: 4482.2349 - val_loss: 7767.9897 - val_mse: 7704.4429 - val_nasa_loss: 3629.6885\n",
            "Epoch 2/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 7033.7588 - mse: 6936.0933 - nasa_loss: 2932.8320 - val_loss: 7451.3408 - val_mse: 7293.2778 - val_nasa_loss: 2944.6316\n",
            "Epoch 3/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 6778.9375 - mse: 6587.9409 - nasa_loss: 2418.4075 - val_loss: 7269.8804 - val_mse: 7002.9390 - val_nasa_loss: 2528.2756\n",
            "Epoch 4/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 6610.8389 - mse: 6288.6309 - nasa_loss: 2077.2249 - val_loss: 7166.3394 - val_mse: 6792.1909 - val_nasa_loss: 2257.3909\n",
            "Epoch 5/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 6523.9248 - mse: 6089.4424 - nasa_loss: 1853.5502 - val_loss: 7109.5444 - val_mse: 6641.5098 - val_nasa_loss: 2078.6416\n",
            "Val asymm loss: 7109.5444\n",
            "Val NASA loss : 2078.6416\n",
            "Val mse loss : 6641.5098\n",
            "Testing: Layer1=50 -> Layer2=32 ... Epoch 1/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 7631.1865 - mse: 7607.6426 - nasa_loss: 4257.3418 - val_loss: 7589.0342 - val_mse: 7442.7930 - val_nasa_loss: 3180.0715\n",
            "Epoch 2/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 6844.6177 - mse: 6645.7158 - nasa_loss: 2547.0928 - val_loss: 7391.4878 - val_mse: 7116.4312 - val_nasa_loss: 2684.8308\n",
            "Epoch 3/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 6632.3892 - mse: 6295.0078 - nasa_loss: 2167.9377 - val_loss: 7295.5615 - val_mse: 6898.6821 - val_nasa_loss: 2391.1272\n",
            "Epoch 4/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 6720.8667 - mse: 6255.4209 - nasa_loss: 1997.8042 - val_loss: 7253.7559 - val_mse: 6765.2168 - val_nasa_loss: 2224.5017\n",
            "Epoch 5/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 6707.6758 - mse: 6175.0132 - nasa_loss: 1885.9783 - val_loss: 7235.3887 - val_mse: 6684.6934 - val_nasa_loss: 2128.6709\n",
            "Val asymm loss: 7235.3887\n",
            "Val NASA loss : 2128.6709\n",
            "Val mse loss : 6684.6934\n",
            "Testing: Layer1=50 -> Layer2=64 ... Epoch 1/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - loss: 7392.5400 - mse: 7391.6372 - nasa_loss: 3828.5200 - val_loss: 6759.1265 - val_mse: 6754.1084 - val_nasa_loss: 2211.0557\n",
            "Epoch 2/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 5978.7915 - mse: 5971.6626 - nasa_loss: 1710.7919 - val_loss: 6087.9941 - val_mse: 6075.5518 - val_nasa_loss: 1506.5665\n",
            "Epoch 3/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 5412.6631 - mse: 5396.6704 - nasa_loss: 1188.0955 - val_loss: 5531.9199 - val_mse: 5508.5132 - val_nasa_loss: 1067.5320\n",
            "Epoch 4/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 4846.0718 - mse: 4817.2051 - nasa_loss: 830.7729 - val_loss: 5055.4512 - val_mse: 5017.3267 - val_nasa_loss: 775.1400\n",
            "Epoch 5/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 4441.3516 - mse: 4396.6626 - nasa_loss: 608.8844 - val_loss: 4643.0625 - val_mse: 4586.3784 - val_nasa_loss: 573.6432\n",
            "Val asymm loss: 4643.0625\n",
            "Val NASA loss : 573.6432\n",
            "Val mse loss : 4586.3784\n",
            "Testing: Layer1=50 -> Layer2=64 ... Epoch 1/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 7111.2417 - mse: 7105.0820 - nasa_loss: 3456.1350 - val_loss: 6470.4849 - val_mse: 6439.0786 - val_nasa_loss: 1856.7760\n",
            "Epoch 2/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 5677.5557 - mse: 5634.6162 - nasa_loss: 1420.7795 - val_loss: 5851.3584 - val_mse: 5781.5298 - val_nasa_loss: 1263.9448\n",
            "Epoch 3/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 5222.4082 - mse: 5136.6567 - nasa_loss: 1004.2315 - val_loss: 5379.8174 - val_mse: 5259.2124 - val_nasa_loss: 909.9991\n",
            "Epoch 4/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 4735.0151 - mse: 4588.9956 - nasa_loss: 715.0759 - val_loss: 5002.3525 - val_mse: 4818.7119 - val_nasa_loss: 676.4695\n",
            "Epoch 5/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 4451.4502 - mse: 4233.6299 - nasa_loss: 537.8665 - val_loss: 4701.1753 - val_mse: 4443.9082 - val_nasa_loss: 516.7915\n",
            "Val asymm loss: 4701.1753\n",
            "Val NASA loss : 516.7915\n",
            "Val mse loss : 4443.9082\n",
            "Testing: Layer1=50 -> Layer2=64 ... Epoch 1/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 7394.1987 - mse: 7388.2441 - nasa_loss: 3857.2173 - val_loss: 7001.2241 - val_mse: 6969.0415 - val_nasa_loss: 2482.9705\n",
            "Epoch 2/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 6184.3257 - mse: 6136.8833 - nasa_loss: 1909.1382 - val_loss: 6385.5620 - val_mse: 6300.8604 - val_nasa_loss: 1716.6375\n",
            "Epoch 3/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 5713.7461 - mse: 5605.7598 - nasa_loss: 1357.5670 - val_loss: 5920.2432 - val_mse: 5759.2026 - val_nasa_loss: 1246.8831\n",
            "Epoch 4/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 5265.8159 - mse: 5073.8809 - nasa_loss: 979.5955 - val_loss: 5569.2407 - val_mse: 5311.7002 - val_nasa_loss: 941.5410\n",
            "Epoch 5/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 5026.7510 - mse: 4731.9961 - nasa_loss: 760.9040 - val_loss: 5310.2876 - val_mse: 4941.7930 - val_nasa_loss: 736.3881\n",
            "Val asymm loss: 5310.2876\n",
            "Val NASA loss : 736.3881\n",
            "Val mse loss : 4941.7930\n",
            "Testing: Layer1=50 -> Layer2=64 ... Epoch 1/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - loss: 7330.5132 - mse: 7315.4756 - nasa_loss: 3760.6919 - val_loss: 6891.6782 - val_mse: 6803.1924 - val_nasa_loss: 2270.9065\n",
            "Epoch 2/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 6134.2075 - mse: 6006.8525 - nasa_loss: 1757.8127 - val_loss: 6382.9985 - val_mse: 6173.0205 - val_nasa_loss: 1594.7439\n",
            "Epoch 3/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 5644.1465 - mse: 5379.4780 - nasa_loss: 1226.7490 - val_loss: 6061.3994 - val_mse: 5697.7881 - val_nasa_loss: 1200.8910\n",
            "Epoch 4/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 5455.3242 - mse: 5012.1738 - nasa_loss: 957.8569 - val_loss: 5873.1646 - val_mse: 5350.0098 - val_nasa_loss: 965.0989\n",
            "Epoch 5/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 5374.8989 - mse: 4792.3296 - nasa_loss: 795.9676 - val_loss: 5771.6836 - val_mse: 5106.7402 - val_nasa_loss: 823.0378\n",
            "Val asymm loss: 5771.6836\n",
            "Val NASA loss : 823.0378\n",
            "Val mse loss : 5106.7402\n",
            "Testing: Layer1=50 -> Layer2=64 ... Epoch 1/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 7212.1294 - mse: 7168.4663 - nasa_loss: 3531.0059 - val_loss: 6871.0386 - val_mse: 6639.1826 - val_nasa_loss: 2075.9597\n",
            "Epoch 2/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 6175.1748 - mse: 5853.0254 - nasa_loss: 1614.5452 - val_loss: 6579.0200 - val_mse: 6118.0513 - val_nasa_loss: 1544.5201\n",
            "Epoch 3/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 5969.4326 - mse: 5434.3247 - nasa_loss: 1236.8068 - val_loss: 6473.4053 - val_mse: 5824.4365 - val_nasa_loss: 1297.2690\n",
            "Epoch 4/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 5924.4043 - mse: 5198.2759 - nasa_loss: 1069.5643 - val_loss: 6442.2192 - val_mse: 5695.7729 - val_nasa_loss: 1199.6733\n",
            "Epoch 5/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 5890.2422 - mse: 5102.7158 - nasa_loss: 1001.8113 - val_loss: 6399.0835 - val_mse: 5678.0342 - val_nasa_loss: 1194.4261\n",
            "Val asymm loss: 6399.0835\n",
            "Val NASA loss : 1194.4261\n",
            "Val mse loss : 5678.0342\n",
            "Testing: Layer1=50 -> Layer2=64 ... Epoch 1/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 7407.2471 - mse: 7351.8848 - nasa_loss: 3806.3237 - val_loss: 7049.2563 - val_mse: 6752.3330 - val_nasa_loss: 2208.9102\n",
            "Epoch 2/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 6434.8501 - mse: 6054.3325 - nasa_loss: 1775.3278 - val_loss: 6864.9248 - val_mse: 6330.4014 - val_nasa_loss: 1745.8501\n",
            "Epoch 3/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 6260.5576 - mse: 5659.6753 - nasa_loss: 1423.8328 - val_loss: 6821.2812 - val_mse: 6153.1655 - val_nasa_loss: 1576.4585\n",
            "Epoch 4/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 6289.2075 - mse: 5564.9805 - nasa_loss: 1328.9683 - val_loss: 6815.0869 - val_mse: 6116.5854 - val_nasa_loss: 1543.2156\n",
            "Epoch 5/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 6251.2788 - mse: 5510.8916 - nasa_loss: 1295.7477 - val_loss: 6813.3013 - val_mse: 6106.2329 - val_nasa_loss: 1533.9502\n",
            "Val asymm loss: 6813.3013\n",
            "Val NASA loss : 1533.9502\n",
            "Val mse loss : 6106.2329\n",
            "Testing: Layer1=50 -> Layer2=64 ... Epoch 1/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 7362.6934 - mse: 7282.3643 - nasa_loss: 3684.0291 - val_loss: 7159.7407 - val_mse: 6776.5674 - val_nasa_loss: 2238.2954\n",
            "Epoch 2/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 6535.7173 - mse: 6042.0234 - nasa_loss: 1792.8080 - val_loss: 7065.2627 - val_mse: 6472.4624 - val_nasa_loss: 1892.0067\n",
            "Epoch 3/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 6492.2656 - mse: 5826.9009 - nasa_loss: 1589.5956 - val_loss: 7055.6079 - val_mse: 6418.8838 - val_nasa_loss: 1835.8451\n",
            "Epoch 4/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 6466.7441 - mse: 5768.3193 - nasa_loss: 1536.1942 - val_loss: 7051.4712 - val_mse: 6414.8340 - val_nasa_loss: 1832.3516\n",
            "Epoch 5/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 6367.7139 - mse: 5764.1035 - nasa_loss: 1557.1622 - val_loss: 6236.2432 - val_mse: 6108.4458 - val_nasa_loss: 1854.9857\n",
            "Val asymm loss: 6236.2432\n",
            "Val NASA loss : 1854.9857\n",
            "Val mse loss : 6108.4458\n",
            "Testing: Layer1=50 -> Layer2=64 ... Epoch 1/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 7397.9878 - mse: 7320.8452 - nasa_loss: 3774.7241 - val_loss: 7307.1396 - val_mse: 6929.7500 - val_nasa_loss: 2431.3694\n",
            "Epoch 2/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 6613.8062 - mse: 6141.1890 - nasa_loss: 1949.9524 - val_loss: 7231.1997 - val_mse: 6664.2173 - val_nasa_loss: 2104.9346\n",
            "Epoch 3/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 6604.7983 - mse: 6007.9297 - nasa_loss: 1749.0431 - val_loss: 7214.8037 - val_mse: 6644.2197 - val_nasa_loss: 2084.1726\n",
            "Epoch 4/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 6583.6182 - mse: 6049.2334 - nasa_loss: 1810.5282 - val_loss: 6364.0386 - val_mse: 6250.9541 - val_nasa_loss: 1927.9919\n",
            "Epoch 5/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 5483.2480 - mse: 5438.7490 - nasa_loss: 1666.2922 - val_loss: 5282.0889 - val_mse: 5262.9546 - val_nasa_loss: 1385.8199\n",
            "Val asymm loss: 5282.0889\n",
            "Val NASA loss : 1385.8199\n",
            "Val mse loss : 5262.9546\n",
            "Testing: Layer1=50 -> Layer2=128 ... Epoch 1/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - loss: 6924.1655 - mse: 6921.0366 - nasa_loss: 3160.1382 - val_loss: 5825.3384 - val_mse: 5808.3940 - val_nasa_loss: 1284.7202\n",
            "Epoch 2/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 5031.8975 - mse: 5006.5664 - nasa_loss: 922.2188 - val_loss: 4806.4956 - val_mse: 4757.9526 - val_nasa_loss: 648.3128\n",
            "Epoch 3/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 4101.7173 - mse: 4036.4014 - nasa_loss: 466.5513 - val_loss: 4057.8748 - val_mse: 3960.3823 - val_nasa_loss: 355.0718\n",
            "Epoch 4/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 3500.5876 - mse: 3379.1643 - nasa_loss: 266.0132 - val_loss: 3538.3149 - val_mse: 3379.7942 - val_nasa_loss: 214.9452\n",
            "Epoch 5/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 3078.2061 - mse: 2889.0913 - nasa_loss: 165.1993 - val_loss: 3191.0710 - val_mse: 2966.0430 - val_nasa_loss: 144.8848\n",
            "Val asymm loss: 3191.0710\n",
            "Val NASA loss : 144.8848\n",
            "Val mse loss : 2966.0430\n",
            "Testing: Layer1=50 -> Layer2=128 ... Epoch 1/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - loss: 6942.4888 - mse: 6930.3657 - nasa_loss: 3258.1614 - val_loss: 5882.0498 - val_mse: 5814.7588 - val_nasa_loss: 1289.6847\n",
            "Epoch 2/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 5060.1357 - mse: 4965.1860 - nasa_loss: 921.1730 - val_loss: 5021.7246 - val_mse: 4841.9883 - val_nasa_loss: 687.5016\n",
            "Epoch 3/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 4370.6294 - mse: 4134.0132 - nasa_loss: 508.5812 - val_loss: 4469.7505 - val_mse: 4132.9541 - val_nasa_loss: 407.5982\n",
            "Epoch 4/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 3949.0251 - mse: 3555.0674 - nasa_loss: 310.4036 - val_loss: 4157.0850 - val_mse: 3651.8838 - val_nasa_loss: 274.0371\n",
            "Epoch 5/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 3759.1143 - mse: 3173.2678 - nasa_loss: 216.6842 - val_loss: 3998.3750 - val_mse: 3346.2205 - val_nasa_loss: 208.3979\n",
            "Val asymm loss: 3998.3750\n",
            "Val NASA loss : 208.3979\n",
            "Val mse loss : 3346.2205\n",
            "Testing: Layer1=50 -> Layer2=128 ... Epoch 1/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 6882.1509 - mse: 6852.2373 - nasa_loss: 3094.9529 - val_loss: 5953.7861 - val_mse: 5799.8320 - val_nasa_loss: 1278.0665\n",
            "Epoch 2/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 5188.2861 - mse: 4971.9106 - nasa_loss: 931.4340 - val_loss: 5284.8838 - val_mse: 4902.6265 - val_nasa_loss: 716.8923\n",
            "Epoch 3/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 4689.0552 - mse: 4219.1421 - nasa_loss: 541.4884 - val_loss: 4974.6133 - val_mse: 4341.5234 - val_nasa_loss: 478.6595\n",
            "Epoch 4/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 4492.9795 - mse: 3745.7793 - nasa_loss: 374.2171 - val_loss: 4858.3022 - val_mse: 4033.6387 - val_nasa_loss: 376.7049\n",
            "Epoch 5/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 4533.5249 - mse: 3607.6335 - nasa_loss: 313.5558 - val_loss: 4821.2046 - val_mse: 3890.5679 - val_nasa_loss: 335.3373\n",
            "Val asymm loss: 4821.2046\n",
            "Val NASA loss : 335.3373\n",
            "Val mse loss : 3890.5679\n",
            "Testing: Layer1=50 -> Layer2=128 ... Epoch 1/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 6788.4756 - mse: 6695.4619 - nasa_loss: 2935.7031 - val_loss: 5978.8628 - val_mse: 5555.5122 - val_nasa_loss: 1099.4989\n",
            "Epoch 2/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 5326.1816 - mse: 4753.5732 - nasa_loss: 813.1714 - val_loss: 5720.8384 - val_mse: 4946.0029 - val_nasa_loss: 738.5114\n",
            "Epoch 3/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 5267.4927 - mse: 4414.5986 - nasa_loss: 605.2645 - val_loss: 5683.4253 - val_mse: 4777.5776 - val_nasa_loss: 657.3142\n",
            "Epoch 4/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 5273.1855 - mse: 4301.6611 - nasa_loss: 558.8506 - val_loss: 5678.6670 - val_mse: 4748.4116 - val_nasa_loss: 643.9924\n",
            "Epoch 5/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 5330.2124 - mse: 4319.3687 - nasa_loss: 558.3401 - val_loss: 5673.9912 - val_mse: 4730.5552 - val_nasa_loss: 636.1959\n",
            "Val asymm loss: 5673.9912\n",
            "Val NASA loss : 636.1959\n",
            "Val mse loss : 4730.5552\n",
            "Testing: Layer1=50 -> Layer2=128 ... Epoch 1/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 7036.1309 - mse: 6890.5811 - nasa_loss: 3189.9131 - val_loss: 6475.3447 - val_mse: 5831.2490 - val_nasa_loss: 1302.6088\n",
            "Epoch 2/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 5892.4258 - mse: 5131.4258 - nasa_loss: 1034.8523 - val_loss: 6433.6782 - val_mse: 5635.6113 - val_nasa_loss: 1155.7198\n",
            "Epoch 3/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 5924.0591 - mse: 5068.8022 - nasa_loss: 965.8369 - val_loss: 6433.4609 - val_mse: 5636.7549 - val_nasa_loss: 1156.5991\n",
            "Epoch 4/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 5943.5874 - mse: 5079.7202 - nasa_loss: 979.3079 - val_loss: 6402.7910 - val_mse: 5605.3960 - val_nasa_loss: 1138.7700\n",
            "Epoch 5/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 5685.8765 - mse: 4978.2603 - nasa_loss: 968.9034 - val_loss: 5011.5000 - val_mse: 4959.0928 - val_nasa_loss: 1294.3081\n",
            "Val asymm loss: 5011.5000\n",
            "Val NASA loss : 1294.3081\n",
            "Val mse loss : 4959.0928\n",
            "Testing: Layer1=50 -> Layer2=128 ... Epoch 1/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 7152.4492 - mse: 6967.2646 - nasa_loss: 3218.2051 - val_loss: 6818.0923 - val_mse: 6136.7021 - val_nasa_loss: 1561.4755\n",
            "Epoch 2/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 6290.4355 - mse: 5539.9429 - nasa_loss: 1308.5908 - val_loss: 6793.1270 - val_mse: 6090.5137 - val_nasa_loss: 1523.4875\n",
            "Epoch 3/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 6068.0493 - mse: 5492.0479 - nasa_loss: 1329.7347 - val_loss: 5213.3809 - val_mse: 5130.6646 - val_nasa_loss: 1632.7292\n",
            "Epoch 4/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 4325.4712 - mse: 4261.0928 - nasa_loss: 1163.9224 - val_loss: 3776.0315 - val_mse: 3721.5891 - val_nasa_loss: 861.7385\n",
            "Epoch 5/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 3138.5229 - mse: 3087.1877 - nasa_loss: 792.4849 - val_loss: 2936.0652 - val_mse: 2883.7104 - val_nasa_loss: 679.6136\n",
            "Val asymm loss: 2936.0652\n",
            "Val NASA loss : 679.6136\n",
            "Val mse loss : 2883.7104\n",
            "Testing: Layer1=50 -> Layer2=128 ... Epoch 1/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - loss: 7233.7466 - mse: 7014.3794 - nasa_loss: 3344.1082 - val_loss: 7050.5869 - val_mse: 6409.7407 - val_nasa_loss: 1827.0759\n",
            "Epoch 2/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 6470.3706 - mse: 5806.5977 - nasa_loss: 1534.8284 - val_loss: 6301.3726 - val_mse: 6002.3403 - val_nasa_loss: 1612.4604\n",
            "Epoch 3/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 5352.9204 - mse: 5167.7046 - nasa_loss: 1465.0641 - val_loss: 4713.5269 - val_mse: 4623.1084 - val_nasa_loss: 1184.3677\n",
            "Epoch 4/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 3920.9478 - mse: 3838.9543 - nasa_loss: 1033.3680 - val_loss: 3673.5439 - val_mse: 3645.2390 - val_nasa_loss: 1005.8509\n",
            "Epoch 5/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 3046.6733 - mse: 2965.6528 - nasa_loss: 844.0582 - val_loss: 2962.0229 - val_mse: 2944.5337 - val_nasa_loss: 877.4789\n",
            "Val asymm loss: 2962.0229\n",
            "Val NASA loss : 877.4789\n",
            "Val mse loss : 2944.5337\n",
            "Testing: Layer1=50 -> Layer2=128 ... Epoch 1/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - loss: 7208.8130 - mse: 6897.7427 - nasa_loss: 3109.0132 - val_loss: 7144.8740 - val_mse: 6715.1660 - val_nasa_loss: 2191.0349\n",
            "Epoch 2/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 6174.6387 - mse: 5830.5068 - nasa_loss: 1746.8446 - val_loss: 5261.8252 - val_mse: 5218.4712 - val_nasa_loss: 1565.7218\n",
            "Epoch 3/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 4352.6138 - mse: 4287.5850 - nasa_loss: 1176.0652 - val_loss: 4160.7847 - val_mse: 4155.8716 - val_nasa_loss: 1179.4388\n",
            "Epoch 4/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 3462.4395 - mse: 3396.0015 - nasa_loss: 893.6971 - val_loss: 3238.5217 - val_mse: 3235.7097 - val_nasa_loss: 955.9905\n",
            "Epoch 5/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 2798.0603 - mse: 2724.8538 - nasa_loss: 794.7704 - val_loss: 2695.1936 - val_mse: 2672.9509 - val_nasa_loss: 1162.9072\n",
            "Val asymm loss: 2695.1936\n",
            "Val NASA loss : 1162.9072\n",
            "Val mse loss : 2672.9509\n",
            "Testing: Layer1=50 -> Layer2=256 ... Epoch 1/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 6025.9712 - mse: 6011.1489 - nasa_loss: 2209.0144 - val_loss: 4325.0479 - val_mse: 4248.8188 - val_nasa_loss: 446.0042\n",
            "Epoch 2/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 3541.4761 - mse: 3428.7607 - nasa_loss: 286.4166 - val_loss: 3267.2146 - val_mse: 3059.5281 - val_nasa_loss: 158.7350\n",
            "Epoch 3/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 2833.3228 - mse: 2576.4038 - nasa_loss: 117.8836 - val_loss: 2832.3220 - val_mse: 2484.4902 - val_nasa_loss: 91.8949\n",
            "Epoch 4/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 2539.1025 - mse: 2136.5291 - nasa_loss: 77.2721 - val_loss: 2686.1599 - val_mse: 2238.8794 - val_nasa_loss: 79.3801\n",
            "Epoch 5/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 2500.5747 - mse: 2002.0930 - nasa_loss: 74.6540 - val_loss: 2638.8445 - val_mse: 2135.1262 - val_nasa_loss: 79.0156\n",
            "Val asymm loss: 2638.8445\n",
            "Val NASA loss : 79.0156\n",
            "Val mse loss : 2135.1262\n",
            "Testing: Layer1=50 -> Layer2=256 ... Epoch 1/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 6217.0532 - mse: 6162.5762 - nasa_loss: 2383.5132 - val_loss: 4627.5874 - val_mse: 4347.7271 - val_nasa_loss: 480.9062\n",
            "Epoch 2/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 4001.6633 - mse: 3600.0632 - nasa_loss: 321.3134 - val_loss: 3997.0815 - val_mse: 3343.3545 - val_nasa_loss: 207.8457\n",
            "Epoch 3/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 3626.0874 - mse: 2857.1470 - nasa_loss: 158.5781 - val_loss: 3876.9146 - val_mse: 3010.8076 - val_nasa_loss: 151.3757\n",
            "Epoch 4/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 3613.8323 - mse: 2665.1558 - nasa_loss: 127.3057 - val_loss: 3863.4531 - val_mse: 2953.7170 - val_nasa_loss: 143.1429\n",
            "Epoch 5/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 3589.5613 - mse: 2595.5847 - nasa_loss: 121.7110 - val_loss: 3857.4814 - val_mse: 2924.3411 - val_nasa_loss: 139.0724\n",
            "Val asymm loss: 3857.4814\n",
            "Val NASA loss : 139.0724\n",
            "Val mse loss : 2924.3411\n",
            "Testing: Layer1=50 -> Layer2=256 ... Epoch 1/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - loss: 6284.3828 - mse: 6157.1270 - nasa_loss: 2359.6882 - val_loss: 5050.1265 - val_mse: 4498.5767 - val_nasa_loss: 538.0813\n",
            "Epoch 2/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 4527.1025 - mse: 3786.5718 - nasa_loss: 383.8628 - val_loss: 4816.8560 - val_mse: 3872.7542 - val_nasa_loss: 330.4938\n",
            "Epoch 3/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 4487.8833 - mse: 3434.3027 - nasa_loss: 274.8402 - val_loss: 4792.4048 - val_mse: 3819.1433 - val_nasa_loss: 317.3493\n",
            "Epoch 4/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 4266.4702 - mse: 3364.9902 - nasa_loss: 287.4062 - val_loss: 3069.1846 - val_mse: 2959.3735 - val_nasa_loss: 711.1109\n",
            "Epoch 5/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 2314.3279 - mse: 2215.1172 - nasa_loss: 571.2249 - val_loss: 1765.7004 - val_mse: 1554.0720 - val_nasa_loss: 606.3782\n",
            "Val asymm loss: 1765.7004\n",
            "Val NASA loss : 606.3782\n",
            "Val mse loss : 1554.0720\n",
            "Testing: Layer1=50 -> Layer2=256 ... Epoch 1/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 6403.0938 - mse: 6140.5835 - nasa_loss: 2374.6057 - val_loss: 5679.7876 - val_mse: 4756.3418 - val_nasa_loss: 647.6078\n",
            "Epoch 2/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 5189.0933 - mse: 4202.4565 - nasa_loss: 529.2714 - val_loss: 5652.8530 - val_mse: 4745.6611 - val_nasa_loss: 646.1233\n",
            "Epoch 3/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 5087.8975 - mse: 4220.7480 - nasa_loss: 556.8989 - val_loss: 4038.5151 - val_mse: 3651.8867 - val_nasa_loss: 630.6083\n",
            "Epoch 4/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 2954.3091 - mse: 2817.6934 - nasa_loss: 716.3685 - val_loss: 2155.8113 - val_mse: 2120.5530 - val_nasa_loss: 800.7055\n",
            "Epoch 5/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1759.2013 - mse: 1609.0013 - nasa_loss: 668.1622 - val_loss: 1514.6903 - val_mse: 1278.3640 - val_nasa_loss: 714.4870\n",
            "Val asymm loss: 1514.6903\n",
            "Val NASA loss : 714.4870\n",
            "Val mse loss : 1278.3640\n",
            "Testing: Layer1=50 -> Layer2=256 ... Epoch 1/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - loss: 6614.5845 - mse: 6159.3389 - nasa_loss: 2305.4353 - val_loss: 6366.9399 - val_mse: 5577.4888 - val_nasa_loss: 1123.7642\n",
            "Epoch 2/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 5420.4551 - mse: 4866.0962 - nasa_loss: 971.5418 - val_loss: 3843.0232 - val_mse: 3721.8054 - val_nasa_loss: 933.6807\n",
            "Epoch 3/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 3047.3591 - mse: 2928.5249 - nasa_loss: 782.9810 - val_loss: 2364.1379 - val_mse: 2179.2366 - val_nasa_loss: 566.8469\n",
            "Epoch 4/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1882.6475 - mse: 1759.6307 - nasa_loss: 692.6918 - val_loss: 1725.8887 - val_mse: 1549.0391 - val_nasa_loss: 611.7682\n",
            "Epoch 5/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1490.0408 - mse: 1321.2845 - nasa_loss: 674.8658 - val_loss: 1352.5540 - val_mse: 1145.0260 - val_nasa_loss: 683.0333\n",
            "Val asymm loss: 1352.5540\n",
            "Val NASA loss : 683.0333\n",
            "Val mse loss : 1145.0260\n",
            "Testing: Layer1=50 -> Layer2=256 ... Epoch 1/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 6788.3589 - mse: 6326.2173 - nasa_loss: 2459.9375 - val_loss: 6102.3184 - val_mse: 5780.1528 - val_nasa_loss: 1446.3616\n",
            "Epoch 2/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 4763.5229 - mse: 4550.1709 - nasa_loss: 1120.8179 - val_loss: 3581.5461 - val_mse: 3293.6016 - val_nasa_loss: 872.6685\n",
            "Epoch 3/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 2765.6738 - mse: 2632.5996 - nasa_loss: 736.3920 - val_loss: 2453.8811 - val_mse: 2351.3723 - val_nasa_loss: 1067.4633\n",
            "Epoch 4/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 1889.8379 - mse: 1776.1615 - nasa_loss: 746.4675 - val_loss: 1933.1088 - val_mse: 1870.0571 - val_nasa_loss: 971.2853\n",
            "Epoch 5/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 1529.5027 - mse: 1375.6710 - nasa_loss: 758.0507 - val_loss: 1642.7247 - val_mse: 1210.9207 - val_nasa_loss: 758.5826\n",
            "Val asymm loss: 1642.7247\n",
            "Val NASA loss : 758.5826\n",
            "Val mse loss : 1210.9207\n",
            "Testing: Layer1=50 -> Layer2=256 ... Epoch 1/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 6979.8706 - mse: 6568.4497 - nasa_loss: 2735.1243 - val_loss: 6369.3433 - val_mse: 6110.5620 - val_nasa_loss: 1715.5532\n",
            "Epoch 2/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 4978.9692 - mse: 4836.5269 - nasa_loss: 1280.3939 - val_loss: 3789.8374 - val_mse: 3756.0554 - val_nasa_loss: 1133.8647\n",
            "Epoch 3/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 3077.4487 - mse: 2968.3181 - nasa_loss: 818.8343 - val_loss: 2663.2520 - val_mse: 2648.2568 - val_nasa_loss: 892.8364\n",
            "Epoch 4/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 2263.9155 - mse: 2156.2122 - nasa_loss: 812.6114 - val_loss: 1990.7474 - val_mse: 1848.5281 - val_nasa_loss: 762.0326\n",
            "Epoch 5/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 1726.1837 - mse: 1574.1222 - nasa_loss: 727.3198 - val_loss: 1705.5941 - val_mse: 1580.4707 - val_nasa_loss: 605.5651\n",
            "Val asymm loss: 1705.5941\n",
            "Val NASA loss : 605.5651\n",
            "Val mse loss : 1580.4707\n",
            "Testing: Layer1=50 -> Layer2=256 ... Epoch 1/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 6978.9346 - mse: 6586.7935 - nasa_loss: 2736.0771 - val_loss: 6075.5122 - val_mse: 5661.7690 - val_nasa_loss: 1462.5261\n",
            "Epoch 2/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 5282.2617 - mse: 4903.8774 - nasa_loss: 1423.3495 - val_loss: 4935.5469 - val_mse: 4087.5703 - val_nasa_loss: 1080.0825\n",
            "Epoch 3/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 4177.9341 - mse: 3868.4851 - nasa_loss: 1286.1777 - val_loss: 3654.2061 - val_mse: 3493.6809 - val_nasa_loss: 1055.9771\n",
            "Epoch 4/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 2916.7708 - mse: 2760.6492 - nasa_loss: 891.0186 - val_loss: 2837.2534 - val_mse: 2769.7739 - val_nasa_loss: 1113.8881\n",
            "Epoch 5/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 2196.5325 - mse: 2055.9875 - nasa_loss: 808.1362 - val_loss: 1971.1511 - val_mse: 1675.8768 - val_nasa_loss: 731.8985\n",
            "Val asymm loss: 1971.1511\n",
            "Val NASA loss : 731.8985\n",
            "Val mse loss : 1675.8768\n",
            "Testing: Layer1=50 -> Layer2=512 ... Epoch 1/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 29ms/step - loss: 5161.0908 - mse: 5104.0635 - nasa_loss: 1567.4264 - val_loss: 3052.0544 - val_mse: 2789.4622 - val_nasa_loss: 121.8038\n",
            "Epoch 2/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 2629.1353 - mse: 2272.4136 - nasa_loss: 87.5217 - val_loss: 2645.3713 - val_mse: 2151.1990 - val_nasa_loss: 78.7966\n",
            "Epoch 3/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 2481.4563 - mse: 1939.9966 - nasa_loss: 75.8880 - val_loss: 2621.7063 - val_mse: 2087.8501 - val_nasa_loss: 80.3992\n",
            "Epoch 4/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 2496.6318 - mse: 1914.2162 - nasa_loss: 78.6300 - val_loss: 2620.2200 - val_mse: 2083.4604 - val_nasa_loss: 80.5879\n",
            "Epoch 5/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 2495.3938 - mse: 1910.7402 - nasa_loss: 79.6988 - val_loss: 2616.2781 - val_mse: 2084.4258 - val_nasa_loss: 80.3687\n",
            "Val asymm loss: 2616.2781\n",
            "Val NASA loss : 80.3687\n",
            "Val mse loss : 2084.4258\n",
            "Testing: Layer1=50 -> Layer2=512 ... Epoch 1/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 29ms/step - loss: 5331.8638 - mse: 5120.7236 - nasa_loss: 1553.4713 - val_loss: 3906.9221 - val_mse: 3113.5181 - val_nasa_loss: 167.2532\n",
            "Epoch 2/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 3634.6968 - mse: 2691.5869 - nasa_loss: 130.2277 - val_loss: 3854.2236 - val_mse: 2928.6272 - val_nasa_loss: 139.8983\n",
            "Epoch 3/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 3605.1121 - mse: 2600.3540 - nasa_loss: 120.2489 - val_loss: 3788.5498 - val_mse: 2883.4265 - val_nasa_loss: 137.5233\n",
            "Epoch 4/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 3506.2588 - mse: 2546.2046 - nasa_loss: 118.1324 - val_loss: 3433.4700 - val_mse: 2625.1804 - val_nasa_loss: 125.8644\n",
            "Epoch 5/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 2643.1892 - mse: 2124.4792 - nasa_loss: 235.7434 - val_loss: 1347.9019 - val_mse: 1145.6454 - val_nasa_loss: 568.2139\n",
            "Val asymm loss: 1347.9019\n",
            "Val NASA loss : 568.2139\n",
            "Val mse loss : 1145.6454\n",
            "Testing: Layer1=50 -> Layer2=512 ... Epoch 1/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 29ms/step - loss: 5547.8784 - mse: 5127.1870 - nasa_loss: 1569.7224 - val_loss: 4802.3945 - val_mse: 3788.5139 - val_nasa_loss: 307.9896\n",
            "Epoch 2/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 4458.3970 - mse: 3360.0618 - nasa_loss: 258.0563 - val_loss: 4814.2393 - val_mse: 3870.1401 - val_nasa_loss: 329.9761\n",
            "Epoch 3/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 4427.6328 - mse: 3387.6838 - nasa_loss: 263.5604 - val_loss: 4626.3120 - val_mse: 3777.2363 - val_nasa_loss: 323.6904\n",
            "Epoch 4/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 3627.2380 - mse: 3000.7612 - nasa_loss: 394.6889 - val_loss: 1784.4573 - val_mse: 1710.1707 - val_nasa_loss: 728.2871\n",
            "Epoch 5/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 1234.0806 - mse: 1073.1805 - nasa_loss: 618.8995 - val_loss: 897.2604 - val_mse: 754.9180 - val_nasa_loss: 713.3168\n",
            "Val asymm loss: 897.2604\n",
            "Val NASA loss : 713.3168\n",
            "Val mse loss : 754.9180\n",
            "Testing: Layer1=50 -> Layer2=512 ... Epoch 1/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 29ms/step - loss: 5892.3325 - mse: 5274.9248 - nasa_loss: 1641.4961 - val_loss: 5646.3994 - val_mse: 4672.0781 - val_nasa_loss: 612.4370\n",
            "Epoch 2/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 5146.8345 - mse: 4153.2817 - nasa_loss: 508.8606 - val_loss: 5242.3418 - val_mse: 4522.6064 - val_nasa_loss: 600.1101\n",
            "Epoch 3/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 4329.6670 - mse: 3694.9333 - nasa_loss: 589.9292 - val_loss: 3190.7461 - val_mse: 2745.7869 - val_nasa_loss: 782.0401\n",
            "Epoch 4/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 2418.1914 - mse: 2092.6960 - nasa_loss: 645.2695 - val_loss: 1519.7471 - val_mse: 1420.8636 - val_nasa_loss: 719.9926\n",
            "Epoch 5/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 1170.4231 - mse: 993.9242 - nasa_loss: 664.5496 - val_loss: 1152.8912 - val_mse: 878.7738 - val_nasa_loss: 944.6954\n",
            "Val asymm loss: 1152.8912\n",
            "Val NASA loss : 944.6954\n",
            "Val mse loss : 878.7738\n",
            "Testing: Layer1=50 -> Layer2=512 ... Epoch 1/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 29ms/step - loss: 6305.3188 - mse: 5670.7998 - nasa_loss: 1812.1130 - val_loss: 5260.4106 - val_mse: 4871.1475 - val_nasa_loss: 956.9445\n",
            "Epoch 2/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 4626.4312 - mse: 4044.1765 - nasa_loss: 931.3257 - val_loss: 3276.4951 - val_mse: 3113.5779 - val_nasa_loss: 1069.7543\n",
            "Epoch 3/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 2669.8213 - mse: 2381.0376 - nasa_loss: 790.2098 - val_loss: 2223.6179 - val_mse: 2026.5658 - val_nasa_loss: 834.4081\n",
            "Epoch 4/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 1888.6641 - mse: 1591.8910 - nasa_loss: 782.8472 - val_loss: 1548.4790 - val_mse: 1172.7247 - val_nasa_loss: 819.4079\n",
            "Epoch 5/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 1396.2946 - mse: 1126.5156 - nasa_loss: 755.6641 - val_loss: 1239.6923 - val_mse: 1070.5621 - val_nasa_loss: 777.8085\n",
            "Val asymm loss: 1239.6923\n",
            "Val NASA loss : 777.8085\n",
            "Val mse loss : 1070.5621\n",
            "Testing: Layer1=50 -> Layer2=512 ... Epoch 1/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 29ms/step - loss: 6441.2759 - mse: 5892.2144 - nasa_loss: 1983.6851 - val_loss: 4468.3105 - val_mse: 4137.6167 - val_nasa_loss: 1316.6256\n",
            "Epoch 2/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 3770.5242 - mse: 3308.0127 - nasa_loss: 998.9750 - val_loss: 3051.9688 - val_mse: 2828.4373 - val_nasa_loss: 1113.4563\n",
            "Epoch 3/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 2380.6743 - mse: 2133.1257 - nasa_loss: 817.0594 - val_loss: 2037.2278 - val_mse: 1469.0078 - val_nasa_loss: 828.9899\n",
            "Epoch 4/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 1626.7728 - mse: 1387.0751 - nasa_loss: 768.8427 - val_loss: 1419.3644 - val_mse: 1328.5568 - val_nasa_loss: 824.5093\n",
            "Epoch 5/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 1285.2567 - mse: 1084.4231 - nasa_loss: 784.6949 - val_loss: 1335.1655 - val_mse: 1210.3088 - val_nasa_loss: 940.2947\n",
            "Val asymm loss: 1335.1655\n",
            "Val NASA loss : 940.2947\n",
            "Val mse loss : 1210.3088\n",
            "Testing: Layer1=50 -> Layer2=512 ... Epoch 1/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 29ms/step - loss: 6595.2134 - mse: 6072.6455 - nasa_loss: 2165.2383 - val_loss: 4737.6372 - val_mse: 4695.6514 - val_nasa_loss: 1967.6061\n",
            "Epoch 2/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 3642.6455 - mse: 3372.5691 - nasa_loss: 1082.3676 - val_loss: 2701.1501 - val_mse: 2571.6042 - val_nasa_loss: 853.7761\n",
            "Epoch 3/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 2189.0720 - mse: 1994.3954 - nasa_loss: 802.4905 - val_loss: 1870.7405 - val_mse: 1600.7505 - val_nasa_loss: 940.0053\n",
            "Epoch 4/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 1601.9534 - mse: 1394.0131 - nasa_loss: 802.2795 - val_loss: 2153.0298 - val_mse: 1166.1940 - val_nasa_loss: 553.2437\n",
            "Epoch 5/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 1456.3945 - mse: 1214.9031 - nasa_loss: 823.4179 - val_loss: 1330.5488 - val_mse: 1171.2529 - val_nasa_loss: 730.3521\n",
            "Val asymm loss: 1330.5488\n",
            "Val NASA loss : 730.3521\n",
            "Val mse loss : 1171.2529\n",
            "Testing: Layer1=50 -> Layer2=512 ... Epoch 1/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 30ms/step - loss: 6623.8721 - mse: 6187.7236 - nasa_loss: 2330.1406 - val_loss: 4416.5586 - val_mse: 3870.4331 - val_nasa_loss: 1225.3549\n",
            "Epoch 2/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 3333.7173 - mse: 3094.7009 - nasa_loss: 1002.8089 - val_loss: 2584.1990 - val_mse: 2516.7725 - val_nasa_loss: 1013.9392\n",
            "Epoch 3/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 2247.7454 - mse: 1999.1490 - nasa_loss: 892.1409 - val_loss: 1882.1304 - val_mse: 1849.7417 - val_nasa_loss: 833.9875\n",
            "Epoch 4/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 1634.0056 - mse: 1429.0649 - nasa_loss: 765.2761 - val_loss: 1688.6804 - val_mse: 1657.0637 - val_nasa_loss: 933.3444\n",
            "Epoch 5/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 1356.8175 - mse: 1161.6729 - nasa_loss: 840.9567 - val_loss: 2188.5447 - val_mse: 2188.3000 - val_nasa_loss: 953.6584\n",
            "Val asymm loss: 2188.5447\n",
            "Val NASA loss : 953.6584\n",
            "Val mse loss : 2188.3000\n",
            "Testing: Layer1=100 -> Layer2=32 ... Epoch 1/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - loss: 7534.5049 - mse: 7534.1191 - nasa_loss: 4055.3398 - val_loss: 7443.2085 - val_mse: 7441.7271 - val_nasa_loss: 3178.4045\n",
            "Epoch 2/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 6719.6377 - mse: 6717.6362 - nasa_loss: 2609.0225 - val_loss: 7072.9316 - val_mse: 7069.9165 - val_nasa_loss: 2619.7412\n",
            "Epoch 3/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 6257.2593 - mse: 6253.4634 - nasa_loss: 2070.9546 - val_loss: 6715.8228 - val_mse: 6710.4663 - val_nasa_loss: 2158.9541\n",
            "Epoch 4/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 5973.6475 - mse: 5967.2808 - nasa_loss: 1737.5254 - val_loss: 6396.0938 - val_mse: 6387.6865 - val_nasa_loss: 1803.6411\n",
            "Epoch 5/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 5687.5068 - mse: 5676.9873 - nasa_loss: 1460.1187 - val_loss: 6099.0898 - val_mse: 6086.8169 - val_nasa_loss: 1516.5553\n",
            "Val asymm loss: 6099.0898\n",
            "Val NASA loss : 1516.5553\n",
            "Val mse loss : 6086.8169\n",
            "Testing: Layer1=100 -> Layer2=32 ... Epoch 1/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - loss: 7489.3838 - mse: 7488.1069 - nasa_loss: 3983.6472 - val_loss: 7545.6973 - val_mse: 7540.9360 - val_nasa_loss: 3343.0244\n",
            "Epoch 2/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 6733.2646 - mse: 6726.7607 - nasa_loss: 2660.3970 - val_loss: 7165.3647 - val_mse: 7154.9932 - val_nasa_loss: 2739.8171\n",
            "Epoch 3/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 6354.2554 - mse: 6339.9028 - nasa_loss: 2174.5098 - val_loss: 6839.2471 - val_mse: 6821.1294 - val_nasa_loss: 2293.1138\n",
            "Epoch 4/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 6163.9844 - mse: 6140.9858 - nasa_loss: 1880.5736 - val_loss: 6539.0806 - val_mse: 6510.5850 - val_nasa_loss: 1932.8423\n",
            "Epoch 5/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 5863.3755 - mse: 5830.5918 - nasa_loss: 1577.5250 - val_loss: 6263.2910 - val_mse: 6221.6792 - val_nasa_loss: 1640.2921\n",
            "Val asymm loss: 6263.2910\n",
            "Val NASA loss : 1640.2921\n",
            "Val mse loss : 6221.6792\n",
            "Testing: Layer1=100 -> Layer2=32 ... Epoch 1/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - loss: 7415.1021 - mse: 7411.1094 - nasa_loss: 3894.0308 - val_loss: 7360.0137 - val_mse: 7343.7144 - val_nasa_loss: 3022.4092\n",
            "Epoch 2/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 6629.1211 - mse: 6607.7144 - nasa_loss: 2442.1130 - val_loss: 7005.4824 - val_mse: 6973.5449 - val_nasa_loss: 2488.9753\n",
            "Epoch 3/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 6198.8789 - mse: 6157.5156 - nasa_loss: 1973.1346 - val_loss: 6697.6855 - val_mse: 6644.6045 - val_nasa_loss: 2082.1924\n",
            "Epoch 4/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 5964.8081 - mse: 5901.8423 - nasa_loss: 1682.7690 - val_loss: 6423.0747 - val_mse: 6342.8467 - val_nasa_loss: 1758.2794\n",
            "Epoch 5/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 5753.0352 - mse: 5659.1182 - nasa_loss: 1433.9569 - val_loss: 6177.5010 - val_mse: 6063.9683 - val_nasa_loss: 1496.3564\n",
            "Val asymm loss: 6177.5010\n",
            "Val NASA loss : 1496.3564\n",
            "Val mse loss : 6063.9683\n",
            "Testing: Layer1=100 -> Layer2=32 ... Epoch 1/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - loss: 7597.6299 - mse: 7592.4648 - nasa_loss: 4166.4644 - val_loss: 7579.9976 - val_mse: 7558.2563 - val_nasa_loss: 3372.4736\n",
            "Epoch 2/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 6862.5630 - mse: 6833.1396 - nasa_loss: 2746.9609 - val_loss: 7228.9795 - val_mse: 7182.0835 - val_nasa_loss: 2778.9888\n",
            "Epoch 3/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 6519.3560 - mse: 6460.0718 - nasa_loss: 2279.6992 - val_loss: 6933.8018 - val_mse: 6851.7520 - val_nasa_loss: 2331.4160\n",
            "Epoch 4/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 6212.4795 - mse: 6110.6069 - nasa_loss: 1883.1489 - val_loss: 6681.0269 - val_mse: 6553.4824 - val_nasa_loss: 1979.6677\n",
            "Epoch 5/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 5949.1865 - mse: 5795.5205 - nasa_loss: 1595.0225 - val_loss: 6467.6201 - val_mse: 6285.1997 - val_nasa_loss: 1701.3215\n",
            "Val asymm loss: 6467.6201\n",
            "Val NASA loss : 1701.3215\n",
            "Val mse loss : 6285.1997\n",
            "Testing: Layer1=100 -> Layer2=32 ... Epoch 1/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 7680.0498 - mse: 7672.5537 - nasa_loss: 4349.6035 - val_loss: 7680.0825 - val_mse: 7643.5952 - val_nasa_loss: 3520.7466\n",
            "Epoch 2/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 6882.7109 - mse: 6828.9893 - nasa_loss: 2823.5603 - val_loss: 7354.2041 - val_mse: 7273.0684 - val_nasa_loss: 2913.9402\n",
            "Epoch 3/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 6612.6011 - mse: 6509.6841 - nasa_loss: 2347.1494 - val_loss: 7095.1187 - val_mse: 6951.6401 - val_nasa_loss: 2460.0144\n",
            "Epoch 4/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 6357.6450 - mse: 6177.7114 - nasa_loss: 1958.5098 - val_loss: 6897.2529 - val_mse: 6678.1929 - val_nasa_loss: 2121.0566\n",
            "Epoch 5/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 6244.2974 - mse: 5984.4858 - nasa_loss: 1736.5424 - val_loss: 6748.3760 - val_mse: 6444.3584 - val_nasa_loss: 1862.3223\n",
            "Val asymm loss: 6748.3760\n",
            "Val NASA loss : 1862.3223\n",
            "Val mse loss : 6444.3584\n",
            "Testing: Layer1=100 -> Layer2=32 ... Epoch 1/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - loss: 7425.7056 - mse: 7397.4272 - nasa_loss: 3862.4443 - val_loss: 7436.1304 - val_mse: 7325.2656 - val_nasa_loss: 2993.7612\n",
            "Epoch 2/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 6736.8306 - mse: 6591.5210 - nasa_loss: 2427.5181 - val_loss: 7194.1812 - val_mse: 6990.6943 - val_nasa_loss: 2511.8425\n",
            "Epoch 3/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 6575.7769 - mse: 6324.8726 - nasa_loss: 2067.5789 - val_loss: 7036.7686 - val_mse: 6729.6030 - val_nasa_loss: 2181.6826\n",
            "Epoch 4/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 6426.6450 - mse: 6044.4683 - nasa_loss: 1815.7200 - val_loss: 6938.5820 - val_mse: 6528.5615 - val_nasa_loss: 1952.3555\n",
            "Epoch 5/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 6365.6538 - mse: 5849.7949 - nasa_loss: 1612.4271 - val_loss: 6880.0142 - val_mse: 6377.0898 - val_nasa_loss: 1792.8359\n",
            "Val asymm loss: 6880.0142\n",
            "Val NASA loss : 1792.8359\n",
            "Val mse loss : 6377.0898\n",
            "Testing: Layer1=100 -> Layer2=32 ... Epoch 1/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 7436.2930 - mse: 7404.3496 - nasa_loss: 3898.9392 - val_loss: 7538.0513 - val_mse: 7414.1782 - val_nasa_loss: 3133.8987\n",
            "Epoch 2/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 6759.9429 - mse: 6600.2310 - nasa_loss: 2493.6824 - val_loss: 7321.9995 - val_mse: 7093.4614 - val_nasa_loss: 2652.5286\n",
            "Epoch 3/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 6671.3862 - mse: 6386.0479 - nasa_loss: 2189.8210 - val_loss: 7193.4619 - val_mse: 6852.9424 - val_nasa_loss: 2332.9155\n",
            "Epoch 4/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 6519.8447 - mse: 6090.7446 - nasa_loss: 1898.1068 - val_loss: 7121.0889 - val_mse: 6675.7900 - val_nasa_loss: 2118.2576\n",
            "Epoch 5/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 6584.4756 - mse: 6058.4263 - nasa_loss: 1781.0126 - val_loss: 7085.2710 - val_mse: 6559.1089 - val_nasa_loss: 1985.8772\n",
            "Val asymm loss: 7085.2710\n",
            "Val NASA loss : 1985.8772\n",
            "Val mse loss : 6559.1089\n",
            "Testing: Layer1=100 -> Layer2=32 ... Epoch 1/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - loss: 7588.1665 - mse: 7548.2808 - nasa_loss: 4085.8318 - val_loss: 7545.4980 - val_mse: 7378.3311 - val_nasa_loss: 3076.7610\n",
            "Epoch 2/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 6858.0830 - mse: 6638.9258 - nasa_loss: 2502.2271 - val_loss: 7372.0396 - val_mse: 7077.5957 - val_nasa_loss: 2630.3967\n",
            "Epoch 3/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 6708.1968 - mse: 6362.8813 - nasa_loss: 2155.5444 - val_loss: 7288.9009 - val_mse: 6880.0796 - val_nasa_loss: 2367.3145\n",
            "Epoch 4/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 6666.3770 - mse: 6192.5088 - nasa_loss: 1961.6921 - val_loss: 7251.0957 - val_mse: 6755.1484 - val_nasa_loss: 2212.3501\n",
            "Epoch 5/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 6678.0366 - mse: 6112.7178 - nasa_loss: 1845.3700 - val_loss: 7235.2354 - val_mse: 6685.6616 - val_nasa_loss: 2129.8621\n",
            "Val asymm loss: 7235.2354\n",
            "Val NASA loss : 2129.8621\n",
            "Val mse loss : 6685.6616\n",
            "Testing: Layer1=100 -> Layer2=64 ... Epoch 1/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 7229.7134 - mse: 7228.6772 - nasa_loss: 3603.4829 - val_loss: 6739.7676 - val_mse: 6734.6011 - val_nasa_loss: 2187.6484\n",
            "Epoch 2/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 5880.9419 - mse: 5873.4751 - nasa_loss: 1644.1381 - val_loss: 6086.1299 - val_mse: 6073.6606 - val_nasa_loss: 1504.8983\n",
            "Epoch 3/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 5370.4321 - mse: 5353.9053 - nasa_loss: 1187.8228 - val_loss: 5538.4814 - val_mse: 5515.2383 - val_nasa_loss: 1072.0616\n",
            "Epoch 4/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 4862.7002 - mse: 4834.0493 - nasa_loss: 835.7532 - val_loss: 5065.5288 - val_mse: 5027.7822 - val_nasa_loss: 780.6269\n",
            "Epoch 5/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 4458.6631 - mse: 4411.6274 - nasa_loss: 618.6280 - val_loss: 4649.4800 - val_mse: 4593.1362 - val_nasa_loss: 576.4539\n",
            "Val asymm loss: 4649.4800\n",
            "Val NASA loss : 576.4539\n",
            "Val mse loss : 4593.1362\n",
            "Testing: Layer1=100 -> Layer2=64 ... Epoch 1/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 7198.3291 - mse: 7192.5200 - nasa_loss: 3515.6753 - val_loss: 6617.8647 - val_mse: 6592.4438 - val_nasa_loss: 2022.9863\n",
            "Epoch 2/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 5849.7095 - mse: 5813.9375 - nasa_loss: 1564.8809 - val_loss: 6014.2124 - val_mse: 5956.9829 - val_nasa_loss: 1404.6206\n",
            "Epoch 3/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 5332.9243 - mse: 5259.5020 - nasa_loss: 1099.4949 - val_loss: 5527.7998 - val_mse: 5425.8296 - val_nasa_loss: 1013.0841\n",
            "Epoch 4/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 4864.3096 - mse: 4737.8569 - nasa_loss: 789.3843 - val_loss: 5130.1523 - val_mse: 4970.7861 - val_nasa_loss: 751.0818\n",
            "Epoch 5/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 4591.6743 - mse: 4400.2690 - nasa_loss: 607.3237 - val_loss: 4810.2842 - val_mse: 4582.8228 - val_nasa_loss: 572.1694\n",
            "Val asymm loss: 4810.2842\n",
            "Val NASA loss : 572.1694\n",
            "Val mse loss : 4582.8228\n",
            "Testing: Layer1=100 -> Layer2=64 ... Epoch 1/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 7347.6362 - mse: 7339.2715 - nasa_loss: 3806.5149 - val_loss: 6854.5063 - val_mse: 6813.2393 - val_nasa_loss: 2283.3237\n",
            "Epoch 2/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 6048.6411 - mse: 5990.9424 - nasa_loss: 1736.1403 - val_loss: 6277.0938 - val_mse: 6178.2739 - val_nasa_loss: 1599.6138\n",
            "Epoch 3/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 5661.0674 - mse: 5533.9170 - nasa_loss: 1282.8586 - val_loss: 5842.8145 - val_mse: 5664.1982 - val_nasa_loss: 1176.3109\n",
            "Epoch 4/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 5190.0337 - mse: 4970.5439 - nasa_loss: 927.1741 - val_loss: 5514.9521 - val_mse: 5237.7808 - val_nasa_loss: 897.3633\n",
            "Epoch 5/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 4945.9419 - mse: 4624.2529 - nasa_loss: 720.5184 - val_loss: 5260.8262 - val_mse: 4864.9263 - val_nasa_loss: 698.5099\n",
            "Val asymm loss: 5260.8262\n",
            "Val NASA loss : 698.5099\n",
            "Val mse loss : 4864.9263\n",
            "Testing: Layer1=100 -> Layer2=64 ... Epoch 1/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 7296.2104 - mse: 7274.7500 - nasa_loss: 3614.5454 - val_loss: 6852.3628 - val_mse: 6757.4971 - val_nasa_loss: 2215.1589\n",
            "Epoch 2/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 6126.8135 - mse: 5998.9624 - nasa_loss: 1734.7869 - val_loss: 6380.3506 - val_mse: 6169.4478 - val_nasa_loss: 1591.4399\n",
            "Epoch 3/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 5690.2163 - mse: 5416.0356 - nasa_loss: 1246.2490 - val_loss: 6075.6875 - val_mse: 5721.2651 - val_nasa_loss: 1218.3107\n",
            "Epoch 4/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 5517.2217 - mse: 5077.1143 - nasa_loss: 987.0122 - val_loss: 5886.1685 - val_mse: 5377.2056 - val_nasa_loss: 982.1007\n",
            "Epoch 5/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 5333.5659 - mse: 4755.2305 - nasa_loss: 795.4567 - val_loss: 5782.4033 - val_mse: 5136.0449 - val_nasa_loss: 839.2278\n",
            "Val asymm loss: 5782.4033\n",
            "Val NASA loss : 839.2278\n",
            "Val mse loss : 5136.0449\n",
            "Testing: Layer1=100 -> Layer2=64 ... Epoch 1/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 7308.1016 - mse: 7265.6963 - nasa_loss: 3595.1833 - val_loss: 6970.8975 - val_mse: 6783.8047 - val_nasa_loss: 2247.1213\n",
            "Epoch 2/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 6293.7129 - mse: 6048.9111 - nasa_loss: 1765.8604 - val_loss: 6638.3340 - val_mse: 6243.6348 - val_nasa_loss: 1661.1830\n",
            "Epoch 3/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 6030.2466 - mse: 5558.3408 - nasa_loss: 1333.1901 - val_loss: 6501.4321 - val_mse: 5917.3081 - val_nasa_loss: 1371.7699\n",
            "Epoch 4/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 5985.1436 - mse: 5314.2852 - nasa_loss: 1133.4932 - val_loss: 6455.4961 - val_mse: 5752.5254 - val_nasa_loss: 1241.8185\n",
            "Epoch 5/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 5955.2446 - mse: 5169.5625 - nasa_loss: 1043.4528 - val_loss: 6441.2603 - val_mse: 5682.0898 - val_nasa_loss: 1189.3551\n",
            "Val asymm loss: 6441.2603\n",
            "Val NASA loss : 1189.3551\n",
            "Val mse loss : 5682.0898\n",
            "Testing: Layer1=100 -> Layer2=64 ... Epoch 1/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 7252.0107 - mse: 7146.3398 - nasa_loss: 3407.8936 - val_loss: 6944.5767 - val_mse: 6542.3135 - val_nasa_loss: 1967.3909\n",
            "Epoch 2/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 6379.6084 - mse: 5887.2070 - nasa_loss: 1599.2467 - val_loss: 6835.0625 - val_mse: 6219.9863 - val_nasa_loss: 1638.6943\n",
            "Epoch 3/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 6239.3960 - mse: 5558.2705 - nasa_loss: 1347.8285 - val_loss: 6816.2803 - val_mse: 6123.9126 - val_nasa_loss: 1549.8226\n",
            "Epoch 4/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 6299.3921 - mse: 5547.4478 - nasa_loss: 1310.4490 - val_loss: 6812.2222 - val_mse: 6096.8379 - val_nasa_loss: 1525.4995\n",
            "Epoch 5/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 6263.7480 - mse: 5515.0903 - nasa_loss: 1298.1035 - val_loss: 6811.4756 - val_mse: 6092.4482 - val_nasa_loss: 1521.6102\n",
            "Val asymm loss: 6811.4756\n",
            "Val NASA loss : 1521.6102\n",
            "Val mse loss : 6092.4482\n",
            "Testing: Layer1=100 -> Layer2=64 ... Epoch 1/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 7302.3115 - mse: 7187.8438 - nasa_loss: 3515.2878 - val_loss: 7117.8237 - val_mse: 6666.2637 - val_nasa_loss: 2107.1802\n",
            "Epoch 2/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 6521.2266 - mse: 5966.2886 - nasa_loss: 1714.9948 - val_loss: 7060.3110 - val_mse: 6445.1333 - val_nasa_loss: 1863.1367\n",
            "Epoch 3/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 6425.7705 - mse: 5766.6401 - nasa_loss: 1548.8925 - val_loss: 7053.3311 - val_mse: 6400.9014 - val_nasa_loss: 1817.2175\n",
            "Epoch 4/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 6522.7134 - mse: 5833.0840 - nasa_loss: 1558.9043 - val_loss: 7052.3682 - val_mse: 6400.0771 - val_nasa_loss: 1816.5391\n",
            "Epoch 5/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 6472.8184 - mse: 5804.9473 - nasa_loss: 1535.2417 - val_loss: 7053.3730 - val_mse: 6422.2295 - val_nasa_loss: 1839.8794\n",
            "Val asymm loss: 7053.3730\n",
            "Val NASA loss : 1839.8794\n",
            "Val mse loss : 6422.2295\n",
            "Testing: Layer1=100 -> Layer2=64 ... Epoch 1/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 7241.1147 - mse: 7133.7305 - nasa_loss: 3500.6541 - val_loss: 7284.3311 - val_mse: 6866.8462 - val_nasa_loss: 2350.4890\n",
            "Epoch 2/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 6641.6328 - mse: 6091.7876 - nasa_loss: 1884.7483 - val_loss: 7226.4600 - val_mse: 6631.1553 - val_nasa_loss: 2066.8008\n",
            "Epoch 3/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 6615.1650 - mse: 5949.3457 - nasa_loss: 1712.3579 - val_loss: 7221.4727 - val_mse: 6594.2979 - val_nasa_loss: 2025.1384\n",
            "Epoch 4/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 6651.1719 - mse: 6012.9570 - nasa_loss: 1744.9563 - val_loss: 7182.3721 - val_mse: 6639.8945 - val_nasa_loss: 2085.6646\n",
            "Epoch 5/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 6402.3179 - mse: 5989.9546 - nasa_loss: 1811.4049 - val_loss: 6014.5098 - val_mse: 5943.0415 - val_nasa_loss: 1834.2461\n",
            "Val asymm loss: 6014.5098\n",
            "Val NASA loss : 1834.2461\n",
            "Val mse loss : 5943.0415\n",
            "Testing: Layer1=100 -> Layer2=128 ... Epoch 1/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 6753.3804 - mse: 6749.8721 - nasa_loss: 2996.6995 - val_loss: 5816.3936 - val_mse: 5799.2764 - val_nasa_loss: 1277.6448\n",
            "Epoch 2/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 4980.9917 - mse: 4955.0298 - nasa_loss: 913.3979 - val_loss: 4817.3003 - val_mse: 4769.2563 - val_nasa_loss: 653.4833\n",
            "Epoch 3/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 4129.1377 - mse: 4066.3992 - nasa_loss: 479.3544 - val_loss: 4090.3660 - val_mse: 3995.7466 - val_nasa_loss: 365.3957\n",
            "Epoch 4/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 3554.6189 - mse: 3436.5825 - nasa_loss: 276.3185 - val_loss: 3576.0967 - val_mse: 3423.2300 - val_nasa_loss: 223.6525\n",
            "Epoch 5/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 3129.6787 - mse: 2950.0400 - nasa_loss: 173.7072 - val_loss: 3218.9312 - val_mse: 3000.4778 - val_nasa_loss: 149.8555\n",
            "Val asymm loss: 3218.9312\n",
            "Val NASA loss : 149.8555\n",
            "Val mse loss : 3000.4778\n",
            "Testing: Layer1=100 -> Layer2=128 ... Epoch 1/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 6851.7217 - mse: 6836.5029 - nasa_loss: 3106.5796 - val_loss: 5810.1187 - val_mse: 5736.7578 - val_nasa_loss: 1229.9154\n",
            "Epoch 2/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 4980.3145 - mse: 4871.6934 - nasa_loss: 871.5275 - val_loss: 4944.3496 - val_mse: 4748.4907 - val_nasa_loss: 644.0126\n",
            "Epoch 3/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 4372.1699 - mse: 4118.6890 - nasa_loss: 485.1367 - val_loss: 4420.4849 - val_mse: 4062.9963 - val_nasa_loss: 385.6472\n",
            "Epoch 4/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 3906.4700 - mse: 3485.9512 - nasa_loss: 294.6355 - val_loss: 4129.1465 - val_mse: 3602.8162 - val_nasa_loss: 262.5629\n",
            "Epoch 5/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 3744.7883 - mse: 3139.0298 - nasa_loss: 209.3327 - val_loss: 3982.2156 - val_mse: 3309.9141 - val_nasa_loss: 201.4942\n",
            "Val asymm loss: 3982.2156\n",
            "Val NASA loss : 201.4942\n",
            "Val mse loss : 3309.9141\n",
            "Testing: Layer1=100 -> Layer2=128 ... Epoch 1/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 6740.5732 - mse: 6701.8096 - nasa_loss: 2887.7419 - val_loss: 5877.0430 - val_mse: 5706.4146 - val_nasa_loss: 1207.2673\n",
            "Epoch 2/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 5159.5854 - mse: 4916.9131 - nasa_loss: 884.1857 - val_loss: 5236.7427 - val_mse: 4826.5137 - val_nasa_loss: 680.1525\n",
            "Epoch 3/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 4697.3174 - mse: 4197.5630 - nasa_loss: 518.6325 - val_loss: 4950.4111 - val_mse: 4286.1660 - val_nasa_loss: 458.9531\n",
            "Epoch 4/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 4527.6440 - mse: 3761.6509 - nasa_loss: 368.0356 - val_loss: 4850.3530 - val_mse: 4006.4919 - val_nasa_loss: 368.5765\n",
            "Epoch 5/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 4451.8716 - mse: 3506.7405 - nasa_loss: 303.2010 - val_loss: 4819.1445 - val_mse: 3880.9333 - val_nasa_loss: 332.6806\n",
            "Val asymm loss: 4819.1445\n",
            "Val NASA loss : 332.6806\n",
            "Val mse loss : 3880.9333\n",
            "Testing: Layer1=100 -> Layer2=128 ... Epoch 1/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - loss: 6841.1313 - mse: 6772.5581 - nasa_loss: 2979.7390 - val_loss: 6137.4790 - val_mse: 5819.5615 - val_nasa_loss: 1293.4407\n",
            "Epoch 2/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 5491.6704 - mse: 5048.0815 - nasa_loss: 967.4471 - val_loss: 5769.9341 - val_mse: 5101.8267 - val_nasa_loss: 820.3469\n",
            "Epoch 3/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 5257.5400 - mse: 4471.6533 - nasa_loss: 650.6837 - val_loss: 5693.0854 - val_mse: 4829.1562 - val_nasa_loss: 681.4032\n",
            "Epoch 4/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 5248.7383 - mse: 4333.4316 - nasa_loss: 572.1400 - val_loss: 5679.8374 - val_mse: 4755.1694 - val_nasa_loss: 647.0470\n",
            "Epoch 5/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 5191.1235 - mse: 4220.2051 - nasa_loss: 542.9785 - val_loss: 5678.6646 - val_mse: 4747.4858 - val_nasa_loss: 643.5569\n",
            "Val asymm loss: 5678.6646\n",
            "Val NASA loss : 643.5569\n",
            "Val mse loss : 4747.4858\n",
            "Testing: Layer1=100 -> Layer2=128 ... Epoch 1/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - loss: 7062.1689 - mse: 6933.3335 - nasa_loss: 3132.8035 - val_loss: 6536.1372 - val_mse: 6014.3140 - val_nasa_loss: 1453.1998\n",
            "Epoch 2/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 5911.9814 - mse: 5257.7603 - nasa_loss: 1124.5070 - val_loss: 6437.5620 - val_mse: 5660.3013 - val_nasa_loss: 1173.4849\n",
            "Epoch 3/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 5906.2964 - mse: 5034.8589 - nasa_loss: 978.2209 - val_loss: 6430.1128 - val_mse: 5608.6235 - val_nasa_loss: 1136.5210\n",
            "Epoch 4/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 5921.1846 - mse: 5059.3350 - nasa_loss: 964.4040 - val_loss: 6432.0845 - val_mse: 5623.8604 - val_nasa_loss: 1147.3245\n",
            "Epoch 5/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 5923.5796 - mse: 5073.3408 - nasa_loss: 980.1281 - val_loss: 6433.6553 - val_mse: 5635.3115 - val_nasa_loss: 1155.5027\n",
            "Val asymm loss: 6433.6553\n",
            "Val NASA loss : 1155.5027\n",
            "Val mse loss : 5635.3115\n",
            "Testing: Layer1=100 -> Layer2=128 ... Epoch 1/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - loss: 6949.4375 - mse: 6667.0239 - nasa_loss: 2808.3208 - val_loss: 6813.7705 - val_mse: 6108.0874 - val_nasa_loss: 1535.5801\n",
            "Epoch 2/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 6299.3760 - mse: 5533.7324 - nasa_loss: 1303.8497 - val_loss: 6805.8569 - val_mse: 6093.5879 - val_nasa_loss: 1523.8528\n",
            "Epoch 3/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 6237.7969 - mse: 5483.3311 - nasa_loss: 1285.7296 - val_loss: 6344.9858 - val_mse: 5991.0596 - val_nasa_loss: 1545.6230\n",
            "Epoch 4/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 5383.2798 - mse: 5090.6006 - nasa_loss: 1253.0450 - val_loss: 4598.9893 - val_mse: 4448.4512 - val_nasa_loss: 1111.4993\n",
            "Epoch 5/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 3721.3936 - mse: 3634.8276 - nasa_loss: 906.7600 - val_loss: 3531.8755 - val_mse: 3528.2219 - val_nasa_loss: 1170.3306\n",
            "Val asymm loss: 3531.8755\n",
            "Val NASA loss : 1170.3306\n",
            "Val mse loss : 3528.2219\n",
            "Testing: Layer1=100 -> Layer2=128 ... Epoch 1/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 7144.2739 - mse: 6884.3540 - nasa_loss: 3093.9424 - val_loss: 7040.6855 - val_mse: 6342.2124 - val_nasa_loss: 1759.1603\n",
            "Epoch 2/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 6384.0791 - mse: 5742.9697 - nasa_loss: 1513.2213 - val_loss: 6235.4385 - val_mse: 6123.6357 - val_nasa_loss: 1921.2023\n",
            "Epoch 3/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 5087.6680 - mse: 4892.8862 - nasa_loss: 1371.0161 - val_loss: 4588.7939 - val_mse: 4536.6533 - val_nasa_loss: 1383.3260\n",
            "Epoch 4/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 3831.2195 - mse: 3743.9951 - nasa_loss: 996.3489 - val_loss: 3571.7610 - val_mse: 3347.9329 - val_nasa_loss: 866.9907\n",
            "Epoch 5/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 2983.2563 - mse: 2889.2319 - nasa_loss: 848.6024 - val_loss: 2972.0076 - val_mse: 2780.3516 - val_nasa_loss: 715.0828\n",
            "Val asymm loss: 2972.0076\n",
            "Val NASA loss : 715.0828\n",
            "Val mse loss : 2780.3516\n",
            "Testing: Layer1=100 -> Layer2=128 ... Epoch 1/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - loss: 7054.9468 - mse: 6739.4536 - nasa_loss: 2901.5293 - val_loss: 7181.1797 - val_mse: 6617.0317 - val_nasa_loss: 2059.4683\n",
            "Epoch 2/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 6386.3076 - mse: 5885.3364 - nasa_loss: 1714.8169 - val_loss: 6120.7988 - val_mse: 5527.1812 - val_nasa_loss: 1315.7362\n",
            "Epoch 3/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 4892.8804 - mse: 4743.4858 - nasa_loss: 1317.2651 - val_loss: 4518.0649 - val_mse: 4273.9727 - val_nasa_loss: 1046.3722\n",
            "Epoch 4/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 3833.8975 - mse: 3693.2622 - nasa_loss: 974.0078 - val_loss: 3586.0693 - val_mse: 3528.6436 - val_nasa_loss: 936.8636\n",
            "Epoch 5/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 3178.7385 - mse: 3058.1470 - nasa_loss: 916.4261 - val_loss: 2903.6501 - val_mse: 2890.7268 - val_nasa_loss: 889.0204\n",
            "Val asymm loss: 2903.6501\n",
            "Val NASA loss : 889.0204\n",
            "Val mse loss : 2890.7268\n",
            "Testing: Layer1=100 -> Layer2=256 ... Epoch 1/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 5978.1309 - mse: 5963.3013 - nasa_loss: 2169.0703 - val_loss: 4391.8896 - val_mse: 4320.2319 - val_nasa_loss: 471.0062\n",
            "Epoch 2/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 3602.2195 - mse: 3496.8147 - nasa_loss: 304.5183 - val_loss: 3337.2471 - val_mse: 3143.9485 - val_nasa_loss: 172.2213\n",
            "Epoch 3/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 2878.7844 - mse: 2632.0693 - nasa_loss: 125.3982 - val_loss: 2872.6433 - val_mse: 2544.0559 - val_nasa_loss: 96.6618\n",
            "Epoch 4/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 2602.2036 - mse: 2217.1851 - nasa_loss: 81.3816 - val_loss: 2703.8193 - val_mse: 2272.6440 - val_nasa_loss: 80.2706\n",
            "Epoch 5/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 2508.1741 - mse: 2019.1906 - nasa_loss: 74.6043 - val_loss: 2646.5010 - val_mse: 2153.8979 - val_nasa_loss: 78.7710\n",
            "Val asymm loss: 2646.5010\n",
            "Val NASA loss : 78.7710\n",
            "Val mse loss : 2153.8979\n",
            "Testing: Layer1=100 -> Layer2=256 ... Epoch 1/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 5927.9521 - mse: 5853.9580 - nasa_loss: 2098.6938 - val_loss: 4504.5137 - val_mse: 4181.4038 - val_nasa_loss: 423.3431\n",
            "Epoch 2/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 3883.5613 - mse: 3430.4373 - nasa_loss: 284.9148 - val_loss: 3967.1938 - val_mse: 3274.7583 - val_nasa_loss: 194.9825\n",
            "Epoch 3/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 3611.3733 - mse: 2811.4453 - nasa_loss: 150.7410 - val_loss: 3874.7375 - val_mse: 3002.2593 - val_nasa_loss: 150.1167\n",
            "Epoch 4/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 3571.9314 - mse: 2625.1372 - nasa_loss: 125.0168 - val_loss: 3860.4312 - val_mse: 2939.1936 - val_nasa_loss: 141.1156\n",
            "Epoch 5/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 3592.8599 - mse: 2602.9182 - nasa_loss: 120.3020 - val_loss: 3861.0034 - val_mse: 2942.0830 - val_nasa_loss: 141.5176\n",
            "Val asymm loss: 3861.0034\n",
            "Val NASA loss : 141.5176\n",
            "Val mse loss : 2942.0830\n",
            "Testing: Layer1=100 -> Layer2=256 ... Epoch 1/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 6135.1929 - mse: 5992.2520 - nasa_loss: 2192.7310 - val_loss: 4998.0728 - val_mse: 4392.5532 - val_nasa_loss: 497.3882\n",
            "Epoch 2/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 4467.3462 - mse: 3682.9895 - nasa_loss: 355.6195 - val_loss: 4808.3354 - val_mse: 3824.8281 - val_nasa_loss: 317.5187\n",
            "Epoch 3/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 4445.1211 - mse: 3386.9795 - nasa_loss: 265.5986 - val_loss: 4808.3701 - val_mse: 3825.0359 - val_nasa_loss: 317.5741\n",
            "Epoch 4/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 4439.5068 - mse: 3391.2168 - nasa_loss: 267.3885 - val_loss: 4801.5596 - val_mse: 3782.6387 - val_nasa_loss: 306.4652\n",
            "Epoch 5/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 4446.2671 - mse: 3381.2000 - nasa_loss: 262.5787 - val_loss: 4807.8325 - val_mse: 3822.9951 - val_nasa_loss: 317.0504\n",
            "Val asymm loss: 4807.8325\n",
            "Val NASA loss : 317.0504\n",
            "Val mse loss : 3822.9951\n",
            "Testing: Layer1=100 -> Layer2=256 ... Epoch 1/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - loss: 6395.4927 - mse: 6144.1255 - nasa_loss: 2295.3916 - val_loss: 5694.8638 - val_mse: 4837.8662 - val_nasa_loss: 685.5398\n",
            "Epoch 2/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 5266.8530 - mse: 4265.4771 - nasa_loss: 558.7874 - val_loss: 5674.4819 - val_mse: 4717.8394 - val_nasa_loss: 630.2288\n",
            "Epoch 3/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 5251.0508 - mse: 4233.1221 - nasa_loss: 535.8145 - val_loss: 5675.6074 - val_mse: 4741.1362 - val_nasa_loss: 640.9046\n",
            "Epoch 4/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 5229.1196 - mse: 4230.8311 - nasa_loss: 538.0653 - val_loss: 5688.0073 - val_mse: 4804.3931 - val_nasa_loss: 669.7837\n",
            "Epoch 5/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 5221.6689 - mse: 4250.2900 - nasa_loss: 559.5407 - val_loss: 5659.9336 - val_mse: 4618.5376 - val_nasa_loss: 587.6221\n",
            "Val asymm loss: 5659.9336\n",
            "Val NASA loss : 587.6221\n",
            "Val mse loss : 4618.5376\n",
            "Testing: Layer1=100 -> Layer2=256 ... Epoch 1/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 6646.0493 - mse: 6191.9785 - nasa_loss: 2316.6194 - val_loss: 6426.8164 - val_mse: 5590.5376 - val_nasa_loss: 1123.9785\n",
            "Epoch 2/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 5893.4795 - mse: 5026.0791 - nasa_loss: 957.9727 - val_loss: 6252.5000 - val_mse: 5607.7603 - val_nasa_loss: 1175.9149\n",
            "Epoch 3/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 5086.5356 - mse: 4615.2095 - nasa_loss: 932.2751 - val_loss: 3697.9575 - val_mse: 3445.5525 - val_nasa_loss: 984.2592\n",
            "Epoch 4/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 2910.2573 - mse: 2732.5823 - nasa_loss: 823.3848 - val_loss: 2469.9551 - val_mse: 2399.3850 - val_nasa_loss: 832.2058\n",
            "Epoch 5/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 2051.3586 - mse: 1827.0441 - nasa_loss: 735.3800 - val_loss: 1746.1281 - val_mse: 1699.6587 - val_nasa_loss: 810.4583\n",
            "Val asymm loss: 1746.1281\n",
            "Val NASA loss : 810.4583\n",
            "Val mse loss : 1699.6587\n",
            "Testing: Layer1=100 -> Layer2=256 ... Epoch 1/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 6742.2861 - mse: 6258.2280 - nasa_loss: 2380.3347 - val_loss: 6475.7637 - val_mse: 6021.8105 - val_nasa_loss: 1540.4625\n",
            "Epoch 2/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 5229.3198 - mse: 4958.0942 - nasa_loss: 1227.2195 - val_loss: 3943.2861 - val_mse: 3765.2463 - val_nasa_loss: 921.3716\n",
            "Epoch 3/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 3186.2893 - mse: 3046.4497 - nasa_loss: 858.1982 - val_loss: 2917.5996 - val_mse: 2794.2949 - val_nasa_loss: 977.2582\n",
            "Epoch 4/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 2332.4919 - mse: 2123.4475 - nasa_loss: 722.1782 - val_loss: 2123.5374 - val_mse: 2076.9751 - val_nasa_loss: 803.0720\n",
            "Epoch 5/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1666.9321 - mse: 1538.4614 - nasa_loss: 701.8942 - val_loss: 1862.1095 - val_mse: 1295.5504 - val_nasa_loss: 565.2336\n",
            "Val asymm loss: 1862.1095\n",
            "Val NASA loss : 565.2336\n",
            "Val mse loss : 1295.5504\n",
            "Testing: Layer1=100 -> Layer2=256 ... Epoch 1/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 6761.0522 - mse: 6279.1816 - nasa_loss: 2305.1772 - val_loss: 6023.5234 - val_mse: 5932.2808 - val_nasa_loss: 1826.0502\n",
            "Epoch 2/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 4788.1816 - mse: 4634.4038 - nasa_loss: 1262.5273 - val_loss: 3789.2798 - val_mse: 3526.7734 - val_nasa_loss: 811.9634\n",
            "Epoch 3/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 3000.2327 - mse: 2865.7996 - nasa_loss: 785.0493 - val_loss: 2663.1663 - val_mse: 2625.2197 - val_nasa_loss: 665.4037\n",
            "Epoch 4/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 2095.5364 - mse: 1975.5372 - nasa_loss: 715.8075 - val_loss: 2041.6427 - val_mse: 1924.6700 - val_nasa_loss: 814.2560\n",
            "Epoch 5/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 2001.4044 - mse: 1816.8889 - nasa_loss: 809.3338 - val_loss: 1621.1768 - val_mse: 1535.0919 - val_nasa_loss: 706.6137\n",
            "Val asymm loss: 1621.1768\n",
            "Val NASA loss : 706.6137\n",
            "Val mse loss : 1535.0919\n",
            "Testing: Layer1=100 -> Layer2=256 ... Epoch 1/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 6939.0977 - mse: 6526.6987 - nasa_loss: 2665.2959 - val_loss: 5768.8159 - val_mse: 5684.6289 - val_nasa_loss: 1815.9285\n",
            "Epoch 2/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 4677.8989 - mse: 4451.0693 - nasa_loss: 1266.4702 - val_loss: 3744.4116 - val_mse: 3535.4287 - val_nasa_loss: 1063.8879\n",
            "Epoch 3/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 2951.2686 - mse: 2818.3914 - nasa_loss: 906.9048 - val_loss: 3010.9746 - val_mse: 2711.7307 - val_nasa_loss: 752.9453\n",
            "Epoch 4/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 2489.2949 - mse: 2298.7231 - nasa_loss: 791.7498 - val_loss: 2000.1473 - val_mse: 1880.0929 - val_nasa_loss: 804.3549\n",
            "Epoch 5/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 1694.5814 - mse: 1540.8914 - nasa_loss: 722.4207 - val_loss: 1682.1256 - val_mse: 1570.5098 - val_nasa_loss: 856.7770\n",
            "Val asymm loss: 1682.1256\n",
            "Val NASA loss : 856.7770\n",
            "Val mse loss : 1570.5098\n",
            "Testing: Layer1=100 -> Layer2=512 ... Epoch 1/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - loss: 4994.3970 - mse: 4936.7974 - nasa_loss: 1431.9749 - val_loss: 3044.3789 - val_mse: 2779.4385 - val_nasa_loss: 120.6156\n",
            "Epoch 2/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 2626.9531 - mse: 2260.4407 - nasa_loss: 86.7049 - val_loss: 2644.6982 - val_mse: 2149.5730 - val_nasa_loss: 78.8135\n",
            "Epoch 3/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 2486.0471 - mse: 1925.7736 - nasa_loss: 77.0712 - val_loss: 2618.5522 - val_mse: 2077.8984 - val_nasa_loss: 80.8512\n",
            "Epoch 4/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 2469.8486 - mse: 1890.0719 - nasa_loss: 78.4077 - val_loss: 2620.2488 - val_mse: 2083.3047 - val_nasa_loss: 80.5982\n",
            "Epoch 5/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 2493.7769 - mse: 1923.4899 - nasa_loss: 78.0289 - val_loss: 2623.3718 - val_mse: 2092.8755 - val_nasa_loss: 80.1942\n",
            "Val asymm loss: 2623.3718\n",
            "Val NASA loss : 80.1942\n",
            "Val mse loss : 2092.8755\n",
            "Testing: Layer1=100 -> Layer2=512 ... Epoch 1/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - loss: 5261.9380 - mse: 5050.9116 - nasa_loss: 1531.9478 - val_loss: 3892.1960 - val_mse: 3066.1501 - val_nasa_loss: 159.7606\n",
            "Epoch 2/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 3592.5193 - mse: 2641.1838 - nasa_loss: 125.1121 - val_loss: 3859.7285 - val_mse: 2935.6965 - val_nasa_loss: 140.6315\n",
            "Epoch 3/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 3616.7163 - mse: 2625.9512 - nasa_loss: 123.1151 - val_loss: 3858.9851 - val_mse: 2931.9548 - val_nasa_loss: 140.1154\n",
            "Epoch 4/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 3630.8867 - mse: 2636.5088 - nasa_loss: 124.5382 - val_loss: 3849.9319 - val_mse: 2880.3337 - val_nasa_loss: 133.1787\n",
            "Epoch 5/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 3622.8975 - mse: 2596.7217 - nasa_loss: 117.3961 - val_loss: 3863.0020 - val_mse: 2955.8230 - val_nasa_loss: 143.4995\n",
            "Val asymm loss: 3863.0020\n",
            "Val NASA loss : 143.4995\n",
            "Val mse loss : 2955.8230\n",
            "Testing: Layer1=100 -> Layer2=512 ... Epoch 1/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - loss: 5338.1362 - mse: 4874.0132 - nasa_loss: 1330.0482 - val_loss: 4798.2500 - val_mse: 3759.6853 - val_nasa_loss: 300.5856\n",
            "Epoch 2/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 4471.6182 - mse: 3408.6289 - nasa_loss: 265.5373 - val_loss: 4801.7559 - val_mse: 3843.5212 - val_nasa_loss: 323.2086\n",
            "Epoch 3/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 4449.6426 - mse: 3403.0720 - nasa_loss: 269.0871 - val_loss: 4808.9922 - val_mse: 3830.1294 - val_nasa_loss: 318.9538\n",
            "Epoch 4/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 4424.9453 - mse: 3349.3596 - nasa_loss: 263.3001 - val_loss: 4685.0776 - val_mse: 3712.8755 - val_nasa_loss: 298.4288\n",
            "Epoch 5/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 3558.3301 - mse: 2934.3113 - nasa_loss: 373.1165 - val_loss: 1486.3572 - val_mse: 1176.1805 - val_nasa_loss: 672.7960\n",
            "Val asymm loss: 1486.3572\n",
            "Val NASA loss : 672.7960\n",
            "Val mse loss : 1176.1805\n",
            "Testing: Layer1=100 -> Layer2=512 ... Epoch 1/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - loss: 5893.2070 - mse: 5285.7168 - nasa_loss: 1565.2622 - val_loss: 5687.2739 - val_mse: 4817.7275 - val_nasa_loss: 676.5302\n",
            "Epoch 2/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 5199.4189 - mse: 4232.9370 - nasa_loss: 541.6059 - val_loss: 5356.4517 - val_mse: 4439.7515 - val_nasa_loss: 551.4828\n",
            "Epoch 3/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 4945.6582 - mse: 4044.6199 - nasa_loss: 566.1147 - val_loss: 5643.6782 - val_mse: 4539.7817 - val_nasa_loss: 556.5036\n",
            "Epoch 4/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 4787.7588 - mse: 3986.3694 - nasa_loss: 987.6557 - val_loss: 4925.2090 - val_mse: 4902.6084 - val_nasa_loss: 2107.3887\n",
            "Epoch 5/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 5401.2993 - mse: 3903.0391 - nasa_loss: 844.5151 - val_loss: 5675.2480 - val_mse: 4771.5566 - val_nasa_loss: 655.4368\n",
            "Val asymm loss: 5675.2480\n",
            "Val NASA loss : 655.4368\n",
            "Val mse loss : 4771.5566\n",
            "Testing: Layer1=100 -> Layer2=512 ... Epoch 1/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - loss: 6290.2710 - mse: 5614.4995 - nasa_loss: 1775.7910 - val_loss: 5118.7573 - val_mse: 4780.3472 - val_nasa_loss: 947.9296\n",
            "Epoch 2/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 3886.1470 - mse: 3617.4109 - nasa_loss: 879.2911 - val_loss: 2520.6445 - val_mse: 2433.2666 - val_nasa_loss: 740.5435\n",
            "Epoch 3/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 1921.0234 - mse: 1727.8734 - nasa_loss: 726.8963 - val_loss: 1585.3223 - val_mse: 1194.2299 - val_nasa_loss: 619.1712\n",
            "Epoch 4/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 1330.3574 - mse: 1125.4967 - nasa_loss: 675.8945 - val_loss: 1355.8104 - val_mse: 804.2983 - val_nasa_loss: 543.1370\n",
            "Epoch 5/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 1251.1785 - mse: 975.5275 - nasa_loss: 771.3229 - val_loss: 996.2424 - val_mse: 875.2820 - val_nasa_loss: 822.8870\n",
            "Val asymm loss: 996.2424\n",
            "Val NASA loss : 822.8870\n",
            "Val mse loss : 875.2820\n",
            "Testing: Layer1=100 -> Layer2=512 ... Epoch 1/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 32ms/step - loss: 6397.2993 - mse: 5827.6226 - nasa_loss: 1959.2244 - val_loss: 5130.8389 - val_mse: 5074.4453 - val_nasa_loss: 1853.2866\n",
            "Epoch 2/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 4808.8687 - mse: 4404.7158 - nasa_loss: 1445.9524 - val_loss: 5892.8486 - val_mse: 5505.6313 - val_nasa_loss: 1491.9626\n",
            "Epoch 3/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 4478.6201 - mse: 4163.5420 - nasa_loss: 1288.0468 - val_loss: 3141.2056 - val_mse: 2791.5049 - val_nasa_loss: 878.2888\n",
            "Epoch 4/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 2487.0991 - mse: 2225.0239 - nasa_loss: 823.7081 - val_loss: 2414.4041 - val_mse: 1932.9844 - val_nasa_loss: 619.3960\n",
            "Epoch 5/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 2015.0724 - mse: 1737.3749 - nasa_loss: 788.4212 - val_loss: 1773.8254 - val_mse: 1541.0343 - val_nasa_loss: 894.6688\n",
            "Val asymm loss: 1773.8254\n",
            "Val NASA loss : 894.6688\n",
            "Val mse loss : 1541.0343\n",
            "Testing: Layer1=100 -> Layer2=512 ... Epoch 1/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - loss: 6606.1724 - mse: 6090.0098 - nasa_loss: 2173.7800 - val_loss: 5889.7900 - val_mse: 4249.5254 - val_nasa_loss: 883.9508\n",
            "Epoch 2/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 5816.6235 - mse: 4380.0200 - nasa_loss: 1016.9415 - val_loss: 7116.4180 - val_mse: 6683.1919 - val_nasa_loss: 2128.8618\n",
            "Epoch 3/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 6440.8789 - mse: 5757.3066 - nasa_loss: 1553.0315 - val_loss: 6987.9678 - val_mse: 6418.6270 - val_nasa_loss: 1848.6499\n",
            "Epoch 4/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 6022.3687 - mse: 5542.1045 - nasa_loss: 1480.1439 - val_loss: 4776.2500 - val_mse: 4685.1045 - val_nasa_loss: 1297.9641\n",
            "Epoch 5/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 3823.5808 - mse: 3686.0510 - nasa_loss: 987.2551 - val_loss: 3162.8271 - val_mse: 3124.2546 - val_nasa_loss: 978.9275\n",
            "Val asymm loss: 3162.8271\n",
            "Val NASA loss : 978.9275\n",
            "Val mse loss : 3124.2546\n",
            "Testing: Layer1=100 -> Layer2=512 ... Epoch 1/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - loss: 6339.1235 - mse: 5920.9590 - nasa_loss: 2167.6157 - val_loss: 4047.7024 - val_mse: 3904.8750 - val_nasa_loss: 1182.1831\n",
            "Epoch 2/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 3160.2578 - mse: 2996.0322 - nasa_loss: 913.6034 - val_loss: 2293.8918 - val_mse: 2197.7039 - val_nasa_loss: 941.0988\n",
            "Epoch 3/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 1907.4756 - mse: 1765.5398 - nasa_loss: 804.3409 - val_loss: 1725.1841 - val_mse: 1685.7441 - val_nasa_loss: 685.4866\n",
            "Epoch 4/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 1653.0117 - mse: 1449.3308 - nasa_loss: 797.6604 - val_loss: 1600.0426 - val_mse: 1577.4666 - val_nasa_loss: 717.1155\n",
            "Epoch 5/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 1351.1417 - mse: 1163.8303 - nasa_loss: 763.4474 - val_loss: 2024.3875 - val_mse: 2006.2039 - val_nasa_loss: 914.8132\n",
            "Val asymm loss: 2024.3875\n",
            "Val NASA loss : 914.8132\n",
            "Val mse loss : 2006.2039\n",
            "Testing: Layer1=150 -> Layer2=32 ... Epoch 1/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - loss: 7522.1235 - mse: 7521.7979 - nasa_loss: 4050.8376 - val_loss: 7546.7183 - val_mse: 7545.5405 - val_nasa_loss: 3350.8374\n",
            "Epoch 2/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 6756.1909 - mse: 6754.4766 - nasa_loss: 2700.5212 - val_loss: 7167.8203 - val_mse: 7165.2744 - val_nasa_loss: 2754.6306\n",
            "Epoch 3/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 6466.2432 - mse: 6462.9448 - nasa_loss: 2260.7986 - val_loss: 6826.9121 - val_mse: 6822.3921 - val_nasa_loss: 2294.6836\n",
            "Epoch 4/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 6068.5415 - mse: 6063.2344 - nasa_loss: 1840.7944 - val_loss: 6509.4712 - val_mse: 6502.2651 - val_nasa_loss: 1923.8663\n",
            "Epoch 5/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 5722.5771 - mse: 5713.6650 - nasa_loss: 1533.2505 - val_loss: 6212.4795 - val_mse: 6201.8149 - val_nasa_loss: 1621.5750\n",
            "Val asymm loss: 6212.4795\n",
            "Val NASA loss : 1621.5750\n",
            "Val mse loss : 6201.8149\n",
            "Testing: Layer1=150 -> Layer2=32 ... Epoch 1/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 7417.5034 - mse: 7416.1152 - nasa_loss: 3901.5652 - val_loss: 7565.2109 - val_mse: 7560.6602 - val_nasa_loss: 3376.5847\n",
            "Epoch 2/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 6789.9595 - mse: 6783.9365 - nasa_loss: 2722.1624 - val_loss: 7207.5801 - val_mse: 7197.9937 - val_nasa_loss: 2802.2090\n",
            "Epoch 3/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 6493.7588 - mse: 6481.6826 - nasa_loss: 2285.1809 - val_loss: 6874.1724 - val_mse: 6857.0430 - val_nasa_loss: 2338.0886\n",
            "Epoch 4/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 6109.9883 - mse: 6087.9897 - nasa_loss: 1877.9532 - val_loss: 6561.3735 - val_mse: 6533.7764 - val_nasa_loss: 1958.0449\n",
            "Epoch 5/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 5902.4199 - mse: 5869.3926 - nasa_loss: 1600.1335 - val_loss: 6275.2422 - val_mse: 6234.2808 - val_nasa_loss: 1652.2596\n",
            "Val asymm loss: 6275.2422\n",
            "Val NASA loss : 1652.2596\n",
            "Val mse loss : 6234.2808\n",
            "Testing: Layer1=150 -> Layer2=32 ... Epoch 1/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 7407.3027 - mse: 7402.9678 - nasa_loss: 3855.2729 - val_loss: 7455.6030 - val_mse: 7442.3022 - val_nasa_loss: 3179.3425\n",
            "Epoch 2/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 6649.3350 - mse: 6632.3394 - nasa_loss: 2547.7634 - val_loss: 7127.5376 - val_mse: 7101.8843 - val_nasa_loss: 2664.3440\n",
            "Epoch 3/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 6313.2920 - mse: 6278.6099 - nasa_loss: 2113.5520 - val_loss: 6813.5732 - val_mse: 6769.4463 - val_nasa_loss: 2229.6355\n",
            "Epoch 4/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 6144.8970 - mse: 6092.5044 - nasa_loss: 1817.7695 - val_loss: 6535.7202 - val_mse: 6467.7427 - val_nasa_loss: 1886.9794\n",
            "Epoch 5/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 5861.9824 - mse: 5782.9683 - nasa_loss: 1541.1172 - val_loss: 6287.8804 - val_mse: 6190.5508 - val_nasa_loss: 1611.0372\n",
            "Val asymm loss: 6287.8804\n",
            "Val NASA loss : 1611.0372\n",
            "Val mse loss : 6190.5508\n",
            "Testing: Layer1=150 -> Layer2=32 ... Epoch 1/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 7427.4487 - mse: 7416.2158 - nasa_loss: 3754.5056 - val_loss: 7348.1763 - val_mse: 7311.4922 - val_nasa_loss: 2972.5310\n",
            "Epoch 2/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 6612.0776 - mse: 6566.4922 - nasa_loss: 2395.8118 - val_loss: 7017.3755 - val_mse: 6946.9336 - val_nasa_loss: 2453.8291\n",
            "Epoch 3/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 6405.2295 - mse: 6318.7432 - nasa_loss: 2016.5983 - val_loss: 6744.2563 - val_mse: 6629.7744 - val_nasa_loss: 2065.2205\n",
            "Epoch 4/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 6019.0986 - mse: 5882.7227 - nasa_loss: 1664.2933 - val_loss: 6513.4136 - val_mse: 6344.3784 - val_nasa_loss: 1759.8146\n",
            "Epoch 5/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 5884.8164 - mse: 5674.9009 - nasa_loss: 1443.2141 - val_loss: 6322.4033 - val_mse: 6090.1279 - val_nasa_loss: 1519.5007\n",
            "Val asymm loss: 6322.4033\n",
            "Val NASA loss : 1519.5007\n",
            "Val mse loss : 6090.1279\n",
            "Testing: Layer1=150 -> Layer2=32 ... Epoch 1/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 7313.1753 - mse: 7289.4551 - nasa_loss: 3655.1299 - val_loss: 7377.4614 - val_mse: 7300.5283 - val_nasa_loss: 2955.7158\n",
            "Epoch 2/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 6564.2812 - mse: 6459.3457 - nasa_loss: 2345.2285 - val_loss: 7102.9575 - val_mse: 6961.8711 - val_nasa_loss: 2473.5061\n",
            "Epoch 3/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 6326.5044 - mse: 6154.6694 - nasa_loss: 1957.8850 - val_loss: 6892.7871 - val_mse: 6671.6094 - val_nasa_loss: 2113.3936\n",
            "Epoch 4/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 6246.7979 - mse: 5972.4375 - nasa_loss: 1732.6179 - val_loss: 6737.3613 - val_mse: 6425.6143 - val_nasa_loss: 1842.7441\n",
            "Epoch 5/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 6136.4238 - mse: 5771.5825 - nasa_loss: 1524.4211 - val_loss: 6628.7979 - val_mse: 6224.5068 - val_nasa_loss: 1642.9725\n",
            "Val asymm loss: 6628.7979\n",
            "Val NASA loss : 1642.9725\n",
            "Val mse loss : 6224.5068\n",
            "Testing: Layer1=150 -> Layer2=32 ... Epoch 1/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 7395.7783 - mse: 7371.7612 - nasa_loss: 3842.7961 - val_loss: 7563.2363 - val_mse: 7483.4321 - val_nasa_loss: 3246.7715\n",
            "Epoch 2/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 6843.2041 - mse: 6723.9380 - nasa_loss: 2634.4648 - val_loss: 7303.8682 - val_mse: 7149.3057 - val_nasa_loss: 2731.6514\n",
            "Epoch 3/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 6613.7930 - mse: 6422.1992 - nasa_loss: 2218.4648 - val_loss: 7106.1362 - val_mse: 6851.0835 - val_nasa_loss: 2330.5752\n",
            "Epoch 4/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 6453.3774 - mse: 6113.6978 - nasa_loss: 1909.4401 - val_loss: 6983.8628 - val_mse: 6626.8853 - val_nasa_loss: 2061.9260\n",
            "Epoch 5/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 6364.5757 - mse: 5936.3564 - nasa_loss: 1705.1479 - val_loss: 6907.6890 - val_mse: 6453.2178 - val_nasa_loss: 1871.6326\n",
            "Val asymm loss: 6907.6890\n",
            "Val NASA loss : 1871.6326\n",
            "Val mse loss : 6453.2178\n",
            "Testing: Layer1=150 -> Layer2=32 ... Epoch 1/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 7540.2158 - mse: 7515.3545 - nasa_loss: 4019.1990 - val_loss: 7654.5815 - val_mse: 7565.7241 - val_nasa_loss: 3385.2461\n",
            "Epoch 2/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 6984.0786 - mse: 6866.0303 - nasa_loss: 2794.9326 - val_loss: 7409.5557 - val_mse: 7231.7720 - val_nasa_loss: 2852.0356\n",
            "Epoch 3/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 6722.9673 - mse: 6495.8818 - nasa_loss: 2330.4202 - val_loss: 7252.6094 - val_mse: 6971.1768 - val_nasa_loss: 2485.8328\n",
            "Epoch 4/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 6591.3647 - mse: 6243.3799 - nasa_loss: 2035.9851 - val_loss: 7160.4653 - val_mse: 6778.2988 - val_nasa_loss: 2240.4055\n",
            "Epoch 5/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 6530.5459 - mse: 6071.1470 - nasa_loss: 1846.2596 - val_loss: 7105.0713 - val_mse: 6627.5225 - val_nasa_loss: 2062.6533\n",
            "Val asymm loss: 7105.0713\n",
            "Val NASA loss : 2062.6533\n",
            "Val mse loss : 6627.5225\n",
            "Testing: Layer1=150 -> Layer2=32 ... Epoch 1/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 7400.1670 - mse: 7331.3208 - nasa_loss: 3652.4602 - val_loss: 7499.1465 - val_mse: 7305.8882 - val_nasa_loss: 2963.9250\n",
            "Epoch 2/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 6775.3921 - mse: 6534.5557 - nasa_loss: 2390.6746 - val_loss: 7344.6753 - val_mse: 7019.1978 - val_nasa_loss: 2550.2363\n",
            "Epoch 3/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 6677.3564 - mse: 6286.8086 - nasa_loss: 2066.1140 - val_loss: 7273.5469 - val_mse: 6833.9897 - val_nasa_loss: 2309.1375\n",
            "Epoch 4/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 6695.5586 - mse: 6170.4355 - nasa_loss: 1937.2681 - val_loss: 7243.4927 - val_mse: 6722.9429 - val_nasa_loss: 2173.7505\n",
            "Epoch 5/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 6607.1211 - mse: 6027.0220 - nasa_loss: 1810.1305 - val_loss: 7231.6953 - val_mse: 6663.9272 - val_nasa_loss: 2104.4792\n",
            "Val asymm loss: 7231.6953\n",
            "Val NASA loss : 2104.4792\n",
            "Val mse loss : 6663.9272\n",
            "Testing: Layer1=150 -> Layer2=64 ... Epoch 1/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - loss: 7306.7085 - mse: 7305.6846 - nasa_loss: 3638.7397 - val_loss: 6921.2334 - val_mse: 6917.3438 - val_nasa_loss: 2415.2217\n",
            "Epoch 2/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 6074.0273 - mse: 6068.4917 - nasa_loss: 1856.0482 - val_loss: 6306.7871 - val_mse: 6297.3330 - val_nasa_loss: 1713.1853\n",
            "Epoch 3/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 5547.6807 - mse: 5535.5054 - nasa_loss: 1333.1050 - val_loss: 5754.0254 - val_mse: 5735.6636 - val_nasa_loss: 1229.0948\n",
            "Epoch 4/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 5058.6528 - mse: 5035.1040 - nasa_loss: 964.6438 - val_loss: 5259.0176 - val_mse: 5227.9194 - val_nasa_loss: 891.5945\n",
            "Epoch 5/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 4595.1904 - mse: 4557.5078 - nasa_loss: 694.4384 - val_loss: 4831.1973 - val_mse: 4783.7891 - val_nasa_loss: 660.1753\n",
            "Val asymm loss: 4831.1973\n",
            "Val NASA loss : 660.1753\n",
            "Val mse loss : 4783.7891\n",
            "Testing: Layer1=150 -> Layer2=64 ... Epoch 1/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - loss: 7041.2583 - mse: 7035.4673 - nasa_loss: 3294.9958 - val_loss: 6680.7021 - val_mse: 6657.5479 - val_nasa_loss: 2097.0991\n",
            "Epoch 2/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 5904.1074 - mse: 5871.8804 - nasa_loss: 1619.5826 - val_loss: 6074.0771 - val_mse: 6020.9751 - val_nasa_loss: 1458.9331\n",
            "Epoch 3/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 5329.9448 - mse: 5262.7549 - nasa_loss: 1138.7822 - val_loss: 5572.9985 - val_mse: 5476.1787 - val_nasa_loss: 1045.9734\n",
            "Epoch 4/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 4990.6714 - mse: 4873.6489 - nasa_loss: 832.4418 - val_loss: 5164.2993 - val_mse: 5010.8643 - val_nasa_loss: 771.7653\n",
            "Epoch 5/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 4549.4155 - mse: 4365.4102 - nasa_loss: 606.2153 - val_loss: 4837.9038 - val_mse: 4617.3721 - val_nasa_loss: 586.6183\n",
            "Val asymm loss: 4837.9038\n",
            "Val NASA loss : 586.6183\n",
            "Val mse loss : 4617.3721\n",
            "Testing: Layer1=150 -> Layer2=64 ... Epoch 1/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - loss: 7184.4111 - mse: 7172.5308 - nasa_loss: 3420.9600 - val_loss: 6793.5835 - val_mse: 6748.0010 - val_nasa_loss: 2203.7183\n",
            "Epoch 2/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 6016.6006 - mse: 5953.8608 - nasa_loss: 1706.6005 - val_loss: 6241.1328 - val_mse: 6137.2065 - val_nasa_loss: 1561.8773\n",
            "Epoch 3/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 5547.4658 - mse: 5415.0332 - nasa_loss: 1221.8619 - val_loss: 5807.8838 - val_mse: 5620.7432 - val_nasa_loss: 1145.1055\n",
            "Epoch 4/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 5138.3940 - mse: 4902.5601 - nasa_loss: 893.0847 - val_loss: 5476.7744 - val_mse: 5184.7896 - val_nasa_loss: 866.7026\n",
            "Epoch 5/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 4941.9321 - mse: 4595.2480 - nasa_loss: 698.8422 - val_loss: 5240.6436 - val_mse: 4832.7866 - val_nasa_loss: 683.1251\n",
            "Val asymm loss: 5240.6436\n",
            "Val NASA loss : 683.1251\n",
            "Val mse loss : 4832.7866\n",
            "Testing: Layer1=150 -> Layer2=64 ... Epoch 1/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 7060.1162 - mse: 7028.5488 - nasa_loss: 3270.0388 - val_loss: 6736.5654 - val_mse: 6620.5576 - val_nasa_loss: 2054.7258\n",
            "Epoch 2/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 5948.1997 - mse: 5788.2661 - nasa_loss: 1582.9473 - val_loss: 6293.3057 - val_mse: 6049.4399 - val_nasa_loss: 1483.6246\n",
            "Epoch 3/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 5634.4629 - mse: 5327.6191 - nasa_loss: 1169.5905 - val_loss: 6011.4077 - val_mse: 5613.0996 - val_nasa_loss: 1139.6851\n",
            "Epoch 4/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 5451.2817 - mse: 4952.5303 - nasa_loss: 920.2044 - val_loss: 5844.6870 - val_mse: 5287.9526 - val_nasa_loss: 927.1681\n",
            "Epoch 5/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 5298.2632 - mse: 4639.7207 - nasa_loss: 745.8820 - val_loss: 5750.7568 - val_mse: 5045.7231 - val_nasa_loss: 790.1108\n",
            "Val asymm loss: 5750.7568\n",
            "Val NASA loss : 790.1108\n",
            "Val mse loss : 5045.7231\n",
            "Testing: Layer1=150 -> Layer2=64 ... Epoch 1/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - loss: 7120.2739 - mse: 7071.2227 - nasa_loss: 3363.1084 - val_loss: 6977.2930 - val_mse: 6792.7432 - val_nasa_loss: 2258.0676\n",
            "Epoch 2/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 6322.8911 - mse: 6068.3721 - nasa_loss: 1777.8080 - val_loss: 6648.9385 - val_mse: 6264.5239 - val_nasa_loss: 1681.2583\n",
            "Epoch 3/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 6027.0112 - mse: 5574.3442 - nasa_loss: 1346.4557 - val_loss: 6508.2549 - val_mse: 5937.6489 - val_nasa_loss: 1388.5343\n",
            "Epoch 4/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 5883.7979 - mse: 5269.9380 - nasa_loss: 1128.9962 - val_loss: 6458.1157 - val_mse: 5763.9385 - val_nasa_loss: 1250.4907\n",
            "Epoch 5/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 5906.8799 - mse: 5156.4468 - nasa_loss: 1035.6989 - val_loss: 6440.5850 - val_mse: 5678.2734 - val_nasa_loss: 1186.5636\n",
            "Val asymm loss: 6440.5850\n",
            "Val NASA loss : 1186.5636\n",
            "Val mse loss : 5678.2734\n",
            "Testing: Layer1=150 -> Layer2=64 ... Epoch 1/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 7154.4272 - mse: 7061.2051 - nasa_loss: 3295.0991 - val_loss: 7055.1113 - val_mse: 6762.9771 - val_nasa_loss: 2221.7925\n",
            "Epoch 2/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 6370.7432 - mse: 5983.0088 - nasa_loss: 1755.4005 - val_loss: 6870.9639 - val_mse: 6349.6636 - val_nasa_loss: 1765.1160\n",
            "Epoch 3/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 6325.9746 - mse: 5700.8213 - nasa_loss: 1467.1272 - val_loss: 6823.9688 - val_mse: 6167.4912 - val_nasa_loss: 1589.6364\n",
            "Epoch 4/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 6255.9175 - mse: 5531.3291 - nasa_loss: 1320.7360 - val_loss: 6814.0142 - val_mse: 6108.8711 - val_nasa_loss: 1536.2610\n",
            "Epoch 5/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 6202.8027 - mse: 5436.0781 - nasa_loss: 1268.1370 - val_loss: 6812.7417 - val_mse: 6100.0288 - val_nasa_loss: 1528.3376\n",
            "Val asymm loss: 6812.7417\n",
            "Val NASA loss : 1528.3376\n",
            "Val mse loss : 6100.0288\n",
            "Testing: Layer1=150 -> Layer2=64 ... Epoch 1/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 7115.9849 - mse: 6971.2456 - nasa_loss: 3257.2922 - val_loss: 7111.2256 - val_mse: 6646.6919 - val_nasa_loss: 2084.5942\n",
            "Epoch 2/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 6455.8989 - mse: 5898.2793 - nasa_loss: 1681.9862 - val_loss: 7059.8330 - val_mse: 6442.4580 - val_nasa_loss: 1860.3342\n",
            "Epoch 3/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 6483.9375 - mse: 5812.8662 - nasa_loss: 1565.8342 - val_loss: 7053.5801 - val_mse: 6402.2466 - val_nasa_loss: 1818.5883\n",
            "Epoch 4/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 6452.8120 - mse: 5751.6729 - nasa_loss: 1535.2832 - val_loss: 7052.8330 - val_mse: 6398.4395 - val_nasa_loss: 1814.7217\n",
            "Epoch 5/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 6489.5737 - mse: 5805.1196 - nasa_loss: 1538.9905 - val_loss: 6991.3521 - val_mse: 6509.1147 - val_nasa_loss: 1955.9264\n",
            "Val asymm loss: 6991.3521\n",
            "Val NASA loss : 1955.9264\n",
            "Val mse loss : 6509.1147\n",
            "Testing: Layer1=150 -> Layer2=64 ... Epoch 1/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - loss: 7279.9272 - mse: 7136.9780 - nasa_loss: 3425.7427 - val_loss: 7271.2705 - val_mse: 6826.7134 - val_nasa_loss: 2300.0601\n",
            "Epoch 2/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 6684.0669 - mse: 6167.7036 - nasa_loss: 1892.0947 - val_loss: 7226.2100 - val_mse: 6629.2710 - val_nasa_loss: 2064.6472\n",
            "Epoch 3/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 6695.3975 - mse: 6044.7275 - nasa_loss: 1780.3540 - val_loss: 7224.4019 - val_mse: 6616.3936 - val_nasa_loss: 2050.0132\n",
            "Epoch 4/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 6651.2920 - mse: 6002.0156 - nasa_loss: 1721.5405 - val_loss: 7226.3604 - val_mse: 6631.9932 - val_nasa_loss: 2067.8040\n",
            "Epoch 5/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 6647.5977 - mse: 5985.9370 - nasa_loss: 1736.1161 - val_loss: 7221.0044 - val_mse: 6612.2261 - val_nasa_loss: 2045.8257\n",
            "Val asymm loss: 7221.0044\n",
            "Val NASA loss : 2045.8257\n",
            "Val mse loss : 6612.2261\n",
            "Testing: Layer1=150 -> Layer2=128 ... Epoch 1/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - loss: 6651.2065 - mse: 6646.5005 - nasa_loss: 2836.9958 - val_loss: 5643.1084 - val_mse: 5622.3506 - val_nasa_loss: 1146.2479\n",
            "Epoch 2/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 4840.0454 - mse: 4810.2266 - nasa_loss: 823.6254 - val_loss: 4675.9414 - val_mse: 4620.9868 - val_nasa_loss: 588.1462\n",
            "Epoch 3/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 4027.8586 - mse: 3956.3901 - nasa_loss: 434.1984 - val_loss: 3978.7600 - val_mse: 3873.8958 - val_nasa_loss: 330.7495\n",
            "Epoch 4/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 3448.8232 - mse: 3318.9568 - nasa_loss: 249.5278 - val_loss: 3491.4465 - val_mse: 3325.5618 - val_nasa_loss: 204.4474\n",
            "Epoch 5/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 3037.3367 - mse: 2842.6111 - nasa_loss: 156.8439 - val_loss: 3159.5833 - val_mse: 2926.7834 - val_nasa_loss: 139.4046\n",
            "Val asymm loss: 3159.5833\n",
            "Val NASA loss : 139.4046\n",
            "Val mse loss : 2926.7834\n",
            "Testing: Layer1=150 -> Layer2=128 ... Epoch 1/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 6567.0859 - mse: 6544.4277 - nasa_loss: 2680.5791 - val_loss: 5627.9390 - val_mse: 5537.0664 - val_nasa_loss: 1086.8629\n",
            "Epoch 2/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 4864.2402 - mse: 4736.3311 - nasa_loss: 782.1475 - val_loss: 4844.3628 - val_mse: 4625.4175 - val_nasa_loss: 590.0229\n",
            "Epoch 3/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 4217.5200 - mse: 3950.3503 - nasa_loss: 440.5156 - val_loss: 4368.6235 - val_mse: 3987.4944 - val_nasa_loss: 362.9670\n",
            "Epoch 4/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 3943.7891 - mse: 3483.8228 - nasa_loss: 285.7916 - val_loss: 4102.9414 - val_mse: 3555.3333 - val_nasa_loss: 251.8093\n",
            "Epoch 5/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 3739.3555 - mse: 3108.2246 - nasa_loss: 203.0318 - val_loss: 3971.1370 - val_mse: 3284.1333 - val_nasa_loss: 196.7025\n",
            "Val asymm loss: 3971.1370\n",
            "Val NASA loss : 196.7025\n",
            "Val mse loss : 3284.1333\n",
            "Testing: Layer1=150 -> Layer2=128 ... Epoch 1/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 6600.7358 - mse: 6552.5176 - nasa_loss: 2663.6433 - val_loss: 5781.8594 - val_mse: 5588.1060 - val_nasa_loss: 1122.1030\n",
            "Epoch 2/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 5065.5562 - mse: 4796.8413 - nasa_loss: 823.1573 - val_loss: 5196.8306 - val_mse: 4761.2656 - val_nasa_loss: 649.8265\n",
            "Epoch 3/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 4663.9575 - mse: 4127.0557 - nasa_loss: 497.3437 - val_loss: 4933.0752 - val_mse: 4244.4575 - val_nasa_loss: 444.5157\n",
            "Epoch 4/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 4475.5684 - mse: 3676.5454 - nasa_loss: 349.4524 - val_loss: 4843.2993 - val_mse: 3981.1235 - val_nasa_loss: 361.1003\n",
            "Epoch 5/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 4471.2065 - mse: 3497.2380 - nasa_loss: 295.9728 - val_loss: 4814.4155 - val_mse: 3857.6750 - val_nasa_loss: 326.3309\n",
            "Val asymm loss: 4814.4155\n",
            "Val NASA loss : 326.3309\n",
            "Val mse loss : 3857.6750\n",
            "Testing: Layer1=150 -> Layer2=128 ... Epoch 1/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 6838.2671 - mse: 6746.6108 - nasa_loss: 2888.4531 - val_loss: 6058.6509 - val_mse: 5693.2407 - val_nasa_loss: 1197.5399\n",
            "Epoch 2/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 5400.4756 - mse: 4895.6069 - nasa_loss: 883.2022 - val_loss: 5736.8184 - val_mse: 5001.4932 - val_nasa_loss: 766.8896\n",
            "Epoch 3/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 5242.9624 - mse: 4381.8315 - nasa_loss: 606.2172 - val_loss: 5684.8281 - val_mse: 4785.4521 - val_nasa_loss: 660.9445\n",
            "Epoch 4/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 5321.6787 - mse: 4328.7451 - nasa_loss: 567.2932 - val_loss: 5679.2212 - val_mse: 4751.2251 - val_nasa_loss: 645.2548\n",
            "Epoch 5/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 5260.2441 - mse: 4251.3271 - nasa_loss: 545.2891 - val_loss: 5678.7656 - val_mse: 4748.8550 - val_nasa_loss: 644.1896\n",
            "Val asymm loss: 5678.7656\n",
            "Val NASA loss : 644.1896\n",
            "Val mse loss : 4748.8550\n",
            "Testing: Layer1=150 -> Layer2=128 ... Epoch 1/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 6962.1753 - mse: 6804.7393 - nasa_loss: 2934.5605 - val_loss: 6505.6348 - val_mse: 5929.9175 - val_nasa_loss: 1382.1431\n",
            "Epoch 2/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 5960.5186 - mse: 5265.2842 - nasa_loss: 1100.8866 - val_loss: 6435.9604 - val_mse: 5650.2559 - val_nasa_loss: 1166.2269\n",
            "Epoch 3/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 5846.3647 - mse: 5014.9404 - nasa_loss: 957.2463 - val_loss: 6434.6680 - val_mse: 5641.7969 - val_nasa_loss: 1160.1420\n",
            "Epoch 4/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 5994.7603 - mse: 5114.1855 - nasa_loss: 996.1898 - val_loss: 6430.8062 - val_mse: 5614.1279 - val_nasa_loss: 1140.4142\n",
            "Epoch 5/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 5931.5996 - mse: 5057.7715 - nasa_loss: 974.6679 - val_loss: 6431.5156 - val_mse: 5619.5859 - val_nasa_loss: 1144.2858\n",
            "Val asymm loss: 6431.5156\n",
            "Val NASA loss : 1144.2858\n",
            "Val mse loss : 5619.5859\n",
            "Testing: Layer1=150 -> Layer2=128 ... Epoch 1/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 6974.9575 - mse: 6746.6167 - nasa_loss: 2880.1697 - val_loss: 6810.4224 - val_mse: 6082.4331 - val_nasa_loss: 1512.6619\n",
            "Epoch 2/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 6266.3960 - mse: 5482.3013 - nasa_loss: 1257.0287 - val_loss: 6812.4194 - val_mse: 6097.6548 - val_nasa_loss: 1526.2133\n",
            "Epoch 3/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 6230.6943 - mse: 5428.2925 - nasa_loss: 1257.0797 - val_loss: 6807.5176 - val_mse: 6057.5708 - val_nasa_loss: 1490.7427\n",
            "Epoch 4/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 6289.1226 - mse: 5480.5640 - nasa_loss: 1267.8722 - val_loss: 6808.3608 - val_mse: 6065.7988 - val_nasa_loss: 1497.9797\n",
            "Epoch 5/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 6226.8486 - mse: 5464.6543 - nasa_loss: 1269.5198 - val_loss: 6811.5771 - val_mse: 6093.9600 - val_nasa_loss: 1522.9766\n",
            "Val asymm loss: 6811.5771\n",
            "Val NASA loss : 1522.9766\n",
            "Val mse loss : 6093.9600\n",
            "Testing: Layer1=150 -> Layer2=128 ... Epoch 1/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 6992.6133 - mse: 6705.1543 - nasa_loss: 2840.3442 - val_loss: 7048.8110 - val_mse: 6363.1865 - val_nasa_loss: 1778.7714\n",
            "Epoch 2/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 6460.8286 - mse: 5737.5151 - nasa_loss: 1509.8707 - val_loss: 7044.0117 - val_mse: 6364.8535 - val_nasa_loss: 1781.3186\n",
            "Epoch 3/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 6520.7979 - mse: 5784.3755 - nasa_loss: 1517.2787 - val_loss: 7121.4712 - val_mse: 6706.5029 - val_nasa_loss: 2157.6182\n",
            "Epoch 4/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 6318.2676 - mse: 5749.3809 - nasa_loss: 1553.9449 - val_loss: 5568.2524 - val_mse: 5282.8647 - val_nasa_loss: 1333.7368\n",
            "Epoch 5/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 4532.7007 - mse: 4427.6855 - nasa_loss: 1176.7719 - val_loss: 4001.9912 - val_mse: 3923.2043 - val_nasa_loss: 1003.8178\n",
            "Val asymm loss: 4001.9912\n",
            "Val NASA loss : 1003.8178\n",
            "Val mse loss : 3923.2043\n",
            "Testing: Layer1=150 -> Layer2=128 ... Epoch 1/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 7022.7358 - mse: 6660.6836 - nasa_loss: 2794.4531 - val_loss: 7225.1147 - val_mse: 6631.6289 - val_nasa_loss: 2067.6189\n",
            "Epoch 2/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 6627.6387 - mse: 6018.7275 - nasa_loss: 1742.2837 - val_loss: 6944.5938 - val_mse: 6746.0029 - val_nasa_loss: 2365.0474\n",
            "Epoch 3/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 5823.4155 - mse: 5605.4609 - nasa_loss: 1696.1182 - val_loss: 5463.0361 - val_mse: 5410.2798 - val_nasa_loss: 1996.0415\n",
            "Epoch 4/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 4623.3521 - mse: 4514.7212 - nasa_loss: 1406.2356 - val_loss: 4399.4814 - val_mse: 4244.0210 - val_nasa_loss: 1254.5444\n",
            "Epoch 5/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 3733.8406 - mse: 3610.8562 - nasa_loss: 1045.2323 - val_loss: 3684.0862 - val_mse: 3266.3699 - val_nasa_loss: 687.0490\n",
            "Val asymm loss: 3684.0862\n",
            "Val NASA loss : 687.0490\n",
            "Val mse loss : 3266.3699\n",
            "Testing: Layer1=150 -> Layer2=256 ... Epoch 1/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 5957.7739 - mse: 5941.8442 - nasa_loss: 2101.0745 - val_loss: 4371.7236 - val_mse: 4298.7158 - val_nasa_loss: 463.3665\n",
            "Epoch 2/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 3598.2971 - mse: 3488.0500 - nasa_loss: 299.6078 - val_loss: 3307.0764 - val_mse: 3107.7500 - val_nasa_loss: 166.3248\n",
            "Epoch 3/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 2885.6675 - mse: 2630.1885 - nasa_loss: 123.3261 - val_loss: 2854.7197 - val_mse: 2517.8542 - val_nasa_loss: 94.4949\n",
            "Epoch 4/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 2606.5286 - mse: 2211.9736 - nasa_loss: 80.6629 - val_loss: 2690.6904 - val_mse: 2247.7280 - val_nasa_loss: 79.5819\n",
            "Epoch 5/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 2509.6597 - mse: 2009.8904 - nasa_loss: 74.5483 - val_loss: 2642.6836 - val_mse: 2144.6833 - val_nasa_loss: 78.8713\n",
            "Val asymm loss: 2642.6836\n",
            "Val NASA loss : 78.8713\n",
            "Val mse loss : 2144.6833\n",
            "Testing: Layer1=150 -> Layer2=256 ... Epoch 1/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 5927.3154 - mse: 5859.7915 - nasa_loss: 2072.0020 - val_loss: 4582.2051 - val_mse: 4287.2671 - val_nasa_loss: 459.3394\n",
            "Epoch 2/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 3984.2246 - mse: 3577.9719 - nasa_loss: 314.8835 - val_loss: 3997.4229 - val_mse: 3344.1233 - val_nasa_loss: 207.9943\n",
            "Epoch 3/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 3643.5640 - mse: 2860.3379 - nasa_loss: 160.1606 - val_loss: 3877.5649 - val_mse: 3013.3679 - val_nasa_loss: 151.7554\n",
            "Epoch 4/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 3625.5901 - mse: 2676.2195 - nasa_loss: 128.2811 - val_loss: 3860.2874 - val_mse: 2938.4751 - val_nasa_loss: 141.0159\n",
            "Epoch 5/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 3637.4324 - mse: 2651.1643 - nasa_loss: 123.3867 - val_loss: 3862.4287 - val_mse: 2948.8726 - val_nasa_loss: 142.4636\n",
            "Val asymm loss: 3862.4287\n",
            "Val NASA loss : 142.4636\n",
            "Val mse loss : 2948.8726\n",
            "Testing: Layer1=150 -> Layer2=256 ... Epoch 1/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - loss: 6040.5840 - mse: 5886.1592 - nasa_loss: 2052.9929 - val_loss: 4989.2349 - val_mse: 4373.6133 - val_nasa_loss: 490.3741\n",
            "Epoch 2/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 4522.1890 - mse: 3714.8174 - nasa_loss: 360.5034 - val_loss: 4811.0454 - val_mse: 3839.9468 - val_nasa_loss: 321.5524\n",
            "Epoch 3/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 4437.9214 - mse: 3360.4275 - nasa_loss: 265.6958 - val_loss: 4804.5522 - val_mse: 3802.2981 - val_nasa_loss: 311.5806\n",
            "Epoch 4/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 4451.4927 - mse: 3367.1360 - nasa_loss: 263.5529 - val_loss: 4803.7720 - val_mse: 3797.8464 - val_nasa_loss: 310.4238\n",
            "Epoch 5/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 4487.0352 - mse: 3392.6365 - nasa_loss: 268.0855 - val_loss: 4799.2969 - val_mse: 3766.5071 - val_nasa_loss: 302.3156\n",
            "Val asymm loss: 4799.2969\n",
            "Val NASA loss : 302.3156\n",
            "Val mse loss : 3766.5071\n",
            "Testing: Layer1=150 -> Layer2=256 ... Epoch 1/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 6284.5356 - mse: 5988.6836 - nasa_loss: 2109.4443 - val_loss: 5681.6675 - val_mse: 4766.7227 - val_nasa_loss: 652.3231\n",
            "Epoch 2/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 5207.8911 - mse: 4202.7988 - nasa_loss: 534.0274 - val_loss: 5674.5181 - val_mse: 4717.9819 - val_nasa_loss: 630.2902\n",
            "Epoch 3/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 5231.5796 - mse: 4208.4971 - nasa_loss: 530.4457 - val_loss: 5683.7417 - val_mse: 4779.1846 - val_nasa_loss: 658.0503\n",
            "Epoch 4/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 5285.7246 - mse: 4278.0273 - nasa_loss: 558.5657 - val_loss: 5674.2954 - val_mse: 4716.3032 - val_nasa_loss: 629.5422\n",
            "Epoch 5/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 5251.8857 - mse: 4235.1831 - nasa_loss: 542.8512 - val_loss: 5680.6807 - val_mse: 4760.6602 - val_nasa_loss: 649.5522\n",
            "Val asymm loss: 5680.6807\n",
            "Val NASA loss : 649.5522\n",
            "Val mse loss : 4760.6602\n",
            "Testing: Layer1=150 -> Layer2=256 ... Epoch 1/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 6429.0801 - mse: 5934.8296 - nasa_loss: 2014.3805 - val_loss: 6431.3486 - val_mse: 5618.5928 - val_nasa_loss: 1143.5862\n",
            "Epoch 2/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 5929.4009 - mse: 5087.4360 - nasa_loss: 986.2700 - val_loss: 6419.5376 - val_mse: 5499.0703 - val_nasa_loss: 1061.4294\n",
            "Epoch 3/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 5906.8911 - mse: 4987.6519 - nasa_loss: 947.1934 - val_loss: 6390.4473 - val_mse: 5595.2344 - val_nasa_loss: 1133.0317\n",
            "Epoch 4/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 5577.0386 - mse: 4945.3838 - nasa_loss: 1034.5042 - val_loss: 4232.2026 - val_mse: 3682.8401 - val_nasa_loss: 737.4894\n",
            "Epoch 5/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 3124.4185 - mse: 2942.5732 - nasa_loss: 722.2614 - val_loss: 2423.5217 - val_mse: 2326.1909 - val_nasa_loss: 745.5101\n",
            "Val asymm loss: 2423.5217\n",
            "Val NASA loss : 745.5101\n",
            "Val mse loss : 2326.1909\n",
            "Testing: Layer1=150 -> Layer2=256 ... Epoch 1/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - loss: 6691.7012 - mse: 6166.8110 - nasa_loss: 2232.8918 - val_loss: 6835.2490 - val_mse: 6244.4810 - val_nasa_loss: 1663.5289\n",
            "Epoch 2/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 6214.8193 - mse: 5577.6504 - nasa_loss: 1372.1981 - val_loss: 5393.8848 - val_mse: 5232.5781 - val_nasa_loss: 1287.7405\n",
            "Epoch 3/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 4224.8872 - mse: 4069.4761 - nasa_loss: 1003.9816 - val_loss: 3633.2695 - val_mse: 2891.0784 - val_nasa_loss: 666.9745\n",
            "Epoch 4/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 2765.8342 - mse: 2552.3418 - nasa_loss: 747.6166 - val_loss: 2631.2041 - val_mse: 2605.0208 - val_nasa_loss: 1085.0879\n",
            "Epoch 5/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 2156.0693 - mse: 1918.7401 - nasa_loss: 795.5273 - val_loss: 1889.6555 - val_mse: 1657.9191 - val_nasa_loss: 834.8371\n",
            "Val asymm loss: 1889.6555\n",
            "Val NASA loss : 834.8371\n",
            "Val mse loss : 1657.9191\n",
            "Testing: Layer1=150 -> Layer2=256 ... Epoch 1/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 6857.5645 - mse: 6377.9722 - nasa_loss: 2451.2639 - val_loss: 6483.6611 - val_mse: 5545.1255 - val_nasa_loss: 1183.4224\n",
            "Epoch 2/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 5174.2583 - mse: 4820.7222 - nasa_loss: 1372.6581 - val_loss: 4521.3633 - val_mse: 4432.8008 - val_nasa_loss: 1447.8743\n",
            "Epoch 3/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 3681.4326 - mse: 3453.6089 - nasa_loss: 982.5486 - val_loss: 3172.6436 - val_mse: 2896.7600 - val_nasa_loss: 849.5968\n",
            "Epoch 4/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 2565.0176 - mse: 2377.0518 - nasa_loss: 843.3483 - val_loss: 2344.1526 - val_mse: 2263.2756 - val_nasa_loss: 1011.6169\n",
            "Epoch 5/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 1905.0325 - mse: 1758.9894 - nasa_loss: 748.2075 - val_loss: 1811.2195 - val_mse: 1670.1825 - val_nasa_loss: 661.4846\n",
            "Val asymm loss: 1811.2195\n",
            "Val NASA loss : 661.4846\n",
            "Val mse loss : 1670.1825\n",
            "Testing: Layer1=150 -> Layer2=256 ... Epoch 1/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 6960.9795 - mse: 6471.7622 - nasa_loss: 2523.6882 - val_loss: 6100.5854 - val_mse: 5943.5771 - val_nasa_loss: 1698.5674\n",
            "Epoch 2/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 5107.8198 - mse: 4895.2979 - nasa_loss: 1493.2257 - val_loss: 4194.5190 - val_mse: 4112.5151 - val_nasa_loss: 1147.6013\n",
            "Epoch 3/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 3417.1121 - mse: 3267.8091 - nasa_loss: 910.9975 - val_loss: 3028.4807 - val_mse: 2699.9165 - val_nasa_loss: 888.1726\n",
            "Epoch 4/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 2344.9956 - mse: 2212.9187 - nasa_loss: 754.3215 - val_loss: 2093.4749 - val_mse: 2041.4435 - val_nasa_loss: 761.4558\n",
            "Epoch 5/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 1853.7695 - mse: 1702.0294 - nasa_loss: 723.7648 - val_loss: 1791.7643 - val_mse: 1669.9420 - val_nasa_loss: 659.0706\n",
            "Val asymm loss: 1791.7643\n",
            "Val NASA loss : 659.0706\n",
            "Val mse loss : 1669.9420\n",
            "Testing: Layer1=150 -> Layer2=512 ... Epoch 1/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 33ms/step - loss: 4912.6694 - mse: 4852.0503 - nasa_loss: 1393.9264 - val_loss: 3017.7764 - val_mse: 2744.4280 - val_nasa_loss: 116.5690\n",
            "Epoch 2/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 2630.3560 - mse: 2264.5952 - nasa_loss: 85.8192 - val_loss: 2644.8660 - val_mse: 2149.9841 - val_nasa_loss: 78.8091\n",
            "Epoch 3/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 2469.4285 - mse: 1925.3555 - nasa_loss: 75.0153 - val_loss: 2620.9814 - val_mse: 2085.5950 - val_nasa_loss: 80.4965\n",
            "Epoch 4/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 2476.7629 - mse: 1902.3682 - nasa_loss: 78.3782 - val_loss: 2620.1204 - val_mse: 2082.9041 - val_nasa_loss: 80.6163\n",
            "Epoch 5/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - loss: 2487.8062 - mse: 1911.6432 - nasa_loss: 77.7880 - val_loss: 2624.6265 - val_mse: 2096.5981 - val_nasa_loss: 80.0517\n",
            "Val asymm loss: 2624.6265\n",
            "Val NASA loss : 80.0517\n",
            "Val mse loss : 2096.5981\n",
            "Testing: Layer1=150 -> Layer2=512 ... Epoch 1/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 34ms/step - loss: 5152.1948 - mse: 4901.3271 - nasa_loss: 1416.8849 - val_loss: 3870.3323 - val_mse: 2984.2039 - val_nasa_loss: 147.4874\n",
            "Epoch 2/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 3603.2720 - mse: 2611.5671 - nasa_loss: 120.1181 - val_loss: 3863.3635 - val_mse: 2953.2913 - val_nasa_loss: 143.0831\n",
            "Epoch 3/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 3589.9724 - mse: 2603.0222 - nasa_loss: 120.2055 - val_loss: 3855.0686 - val_mse: 2911.0913 - val_nasa_loss: 137.2698\n",
            "Epoch 4/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 3666.6272 - mse: 2646.2083 - nasa_loss: 122.2764 - val_loss: 3857.4812 - val_mse: 2924.1565 - val_nasa_loss: 139.0450\n",
            "Epoch 5/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - loss: 3598.6809 - mse: 2595.7451 - nasa_loss: 119.7511 - val_loss: 3854.6140 - val_mse: 2908.5486 - val_nasa_loss: 136.9268\n",
            "Val asymm loss: 3854.6140\n",
            "Val NASA loss : 136.9268\n",
            "Val mse loss : 2908.5486\n",
            "Testing: Layer1=150 -> Layer2=512 ... Epoch 1/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 34ms/step - loss: 5528.4907 - mse: 5110.5781 - nasa_loss: 1559.2625 - val_loss: 4794.2666 - val_mse: 3724.6399 - val_nasa_loss: 291.7437\n",
            "Epoch 2/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - loss: 4514.5566 - mse: 3359.8679 - nasa_loss: 256.5297 - val_loss: 4805.1562 - val_mse: 3805.9670 - val_nasa_loss: 312.5410\n",
            "Epoch 3/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - loss: 4491.0703 - mse: 3419.7146 - nasa_loss: 266.5155 - val_loss: 4820.7324 - val_mse: 3888.4067 - val_nasa_loss: 334.7407\n",
            "Epoch 4/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - loss: 4438.5396 - mse: 3403.1304 - nasa_loss: 267.7619 - val_loss: 4801.8325 - val_mse: 3784.4771 - val_nasa_loss: 306.9405\n",
            "Epoch 5/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - loss: 4449.7866 - mse: 3356.1379 - nasa_loss: 262.3877 - val_loss: 4801.4648 - val_mse: 3781.9714 - val_nasa_loss: 306.2925\n",
            "Val asymm loss: 4801.4648\n",
            "Val NASA loss : 306.2925\n",
            "Val mse loss : 3781.9714\n",
            "Testing: Layer1=150 -> Layer2=512 ... Epoch 1/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 34ms/step - loss: 5851.9185 - mse: 5210.3867 - nasa_loss: 1507.8665 - val_loss: 5672.9009 - val_mse: 4747.1265 - val_nasa_loss: 644.0999\n",
            "Epoch 2/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - loss: 5242.6035 - mse: 4237.2236 - nasa_loss: 536.8309 - val_loss: 5406.4185 - val_mse: 4436.2485 - val_nasa_loss: 536.5015\n",
            "Epoch 3/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - loss: 4824.0391 - mse: 3955.7515 - nasa_loss: 491.0138 - val_loss: 3949.8384 - val_mse: 3047.2693 - val_nasa_loss: 787.8210\n",
            "Epoch 4/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - loss: 3328.7358 - mse: 2682.3364 - nasa_loss: 776.4507 - val_loss: 2358.3240 - val_mse: 1713.2799 - val_nasa_loss: 614.7803\n",
            "Epoch 5/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - loss: 1629.2990 - mse: 1364.7476 - nasa_loss: 630.8502 - val_loss: 1468.5138 - val_mse: 1450.7747 - val_nasa_loss: 916.9462\n",
            "Val asymm loss: 1468.5138\n",
            "Val NASA loss : 916.9462\n",
            "Val mse loss : 1450.7747\n",
            "Testing: Layer1=150 -> Layer2=512 ... Epoch 1/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 34ms/step - loss: 6214.7437 - mse: 5607.3467 - nasa_loss: 1790.8705 - val_loss: 5148.7241 - val_mse: 5064.7681 - val_nasa_loss: 1560.3257\n",
            "Epoch 2/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - loss: 4677.9355 - mse: 4240.9082 - nasa_loss: 1172.9203 - val_loss: 4498.9951 - val_mse: 4019.4177 - val_nasa_loss: 913.7208\n",
            "Epoch 3/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - loss: 4331.8296 - mse: 3297.1099 - nasa_loss: 837.4449 - val_loss: 4350.3701 - val_mse: 3309.8694 - val_nasa_loss: 826.1906\n",
            "Epoch 4/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - loss: 4120.3740 - mse: 3223.2197 - nasa_loss: 1077.2145 - val_loss: 4579.6587 - val_mse: 3402.0801 - val_nasa_loss: 877.8833\n",
            "Epoch 5/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - loss: 3896.3052 - mse: 3401.8181 - nasa_loss: 1036.9891 - val_loss: 4373.1118 - val_mse: 3864.4534 - val_nasa_loss: 1040.7729\n",
            "Val asymm loss: 4373.1118\n",
            "Val NASA loss : 1040.7729\n",
            "Val mse loss : 3864.4534\n",
            "Testing: Layer1=150 -> Layer2=512 ... Epoch 1/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 34ms/step - loss: 6117.2021 - mse: 5614.2886 - nasa_loss: 1835.3608 - val_loss: 5025.4775 - val_mse: 3638.3257 - val_nasa_loss: 986.1427\n",
            "Epoch 2/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - loss: 3976.7266 - mse: 3641.9636 - nasa_loss: 1491.1749 - val_loss: 3186.4644 - val_mse: 3005.8452 - val_nasa_loss: 1036.0154\n",
            "Epoch 3/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - loss: 2499.0645 - mse: 2277.6309 - nasa_loss: 784.5875 - val_loss: 1974.2428 - val_mse: 1677.1605 - val_nasa_loss: 1023.1200\n",
            "Epoch 4/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 1587.7012 - mse: 1407.5289 - nasa_loss: 766.4217 - val_loss: 1797.8928 - val_mse: 1690.4092 - val_nasa_loss: 1010.0343\n",
            "Epoch 5/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - loss: 1378.7670 - mse: 1171.7797 - nasa_loss: 762.9100 - val_loss: 1739.5775 - val_mse: 1424.4615 - val_nasa_loss: 515.9778\n",
            "Val asymm loss: 1739.5775\n",
            "Val NASA loss : 515.9778\n",
            "Val mse loss : 1424.4615\n",
            "Testing: Layer1=150 -> Layer2=512 ... Epoch 1/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 35ms/step - loss: 6406.7163 - mse: 5887.9248 - nasa_loss: 2050.9856 - val_loss: 6591.3628 - val_mse: 4511.8389 - val_nasa_loss: 811.1707\n",
            "Epoch 2/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - loss: 4959.8569 - mse: 4320.6411 - nasa_loss: 1204.2161 - val_loss: 3463.9922 - val_mse: 3320.9111 - val_nasa_loss: 854.5727\n",
            "Epoch 3/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - loss: 2703.0588 - mse: 2537.2664 - nasa_loss: 796.9201 - val_loss: 2466.3037 - val_mse: 2426.9634 - val_nasa_loss: 981.7802\n",
            "Epoch 4/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - loss: 2001.3776 - mse: 1798.3329 - nasa_loss: 815.4968 - val_loss: 1792.0372 - val_mse: 1695.0753 - val_nasa_loss: 709.6334\n",
            "Epoch 5/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - loss: 1547.9305 - mse: 1343.9773 - nasa_loss: 731.7031 - val_loss: 1658.8431 - val_mse: 1428.2825 - val_nasa_loss: 1066.7347\n",
            "Val asymm loss: 1658.8431\n",
            "Val NASA loss : 1066.7347\n",
            "Val mse loss : 1428.2825\n",
            "Testing: Layer1=150 -> Layer2=512 ... Epoch 1/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 34ms/step - loss: 6865.9629 - mse: 6217.5132 - nasa_loss: 2220.4180 - val_loss: 7361.4927 - val_mse: 7064.9697 - val_nasa_loss: 2614.5674\n",
            "Epoch 2/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - loss: 6631.1147 - mse: 6128.7046 - nasa_loss: 1924.6984 - val_loss: 6194.0327 - val_mse: 5942.6157 - val_nasa_loss: 1698.2737\n",
            "Epoch 3/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - loss: 4748.4175 - mse: 4671.2705 - nasa_loss: 1296.8784 - val_loss: 3417.7905 - val_mse: 3319.9978 - val_nasa_loss: 837.0634\n",
            "Epoch 4/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - loss: 2823.5645 - mse: 2632.1018 - nasa_loss: 825.0216 - val_loss: 3078.4514 - val_mse: 2999.0569 - val_nasa_loss: 889.9288\n",
            "Epoch 5/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - loss: 2522.3872 - mse: 2299.6792 - nasa_loss: 781.4629 - val_loss: 2542.8174 - val_mse: 1783.8516 - val_nasa_loss: 598.5151\n",
            "Val asymm loss: 2542.8174\n",
            "Val NASA loss : 598.5151\n",
            "Val mse loss : 1783.8516\n",
            " Final structure : Layer 1 = 50, Layer 2 = 512, alpha = 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "6TN7IXYjcCkR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Final model :\n",
        "input_shape = (X_train.shape[1], X_train.shape[2]) #(30,14)\n",
        "final_model = build_lstm_model(input_shape, 50, 512, 0.2,10)\n",
        "history = final_model.fit(X_train, Y_train,\n",
        "                          epochs=50,\n",
        "                          batch_size=200,\n",
        "                          validation_split=0.2,\n",
        "                          verbose=1)\n",
        "val_loss = history.history['val_loss'][-1]\n",
        "val_mse_loss = history.history['val_mse'][-1]\n",
        "val_NASA_loss = history.history['val_nasa_loss'][-1]\n",
        "print(f\"Val asymm loss: {val_loss:.4f}\")\n",
        "print(f\"Val NASA loss : {val_NASA_loss:.4f}\")\n",
        "print(f\"Val mse loss : {val_mse_loss:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zS6LEf00fCoT",
        "outputId": "d442c481-ff7b-4a53-871b-12b594d5142d"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 33ms/step - loss: 5471.0063 - mse: 5052.9619 - nasa_loss: 1513.5620 - val_loss: 4794.9907 - val_mse: 3732.4895 - val_nasa_loss: 293.7140\n",
            "Epoch 2/50\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 4459.3027 - mse: 3357.1223 - nasa_loss: 259.5288 - val_loss: 4772.7002 - val_mse: 3759.8271 - val_nasa_loss: 302.6439\n",
            "Epoch 3/50\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 4410.5142 - mse: 3339.4907 - nasa_loss: 255.8322 - val_loss: 4806.3994 - val_mse: 3841.0161 - val_nasa_loss: 322.2829\n",
            "Epoch 4/50\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 4349.3491 - mse: 3345.3755 - nasa_loss: 266.4879 - val_loss: 4045.1814 - val_mse: 3324.0308 - val_nasa_loss: 269.7126\n",
            "Epoch 5/50\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 2835.5513 - mse: 2432.4260 - nasa_loss: 387.3929 - val_loss: 1668.8586 - val_mse: 1617.0841 - val_nasa_loss: 490.1034\n",
            "Epoch 6/50\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 1059.0222 - mse: 866.6215 - nasa_loss: 611.4828 - val_loss: 867.7799 - val_mse: 805.0949 - val_nasa_loss: 776.1895\n",
            "Epoch 7/50\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 769.7170 - mse: 579.9045 - nasa_loss: 924.0532 - val_loss: 690.5529 - val_mse: 576.7842 - val_nasa_loss: 1128.7159\n",
            "Epoch 8/50\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 651.3264 - mse: 475.8358 - nasa_loss: 1068.2874 - val_loss: 630.2743 - val_mse: 514.9822 - val_nasa_loss: 1220.5142\n",
            "Epoch 9/50\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 602.7331 - mse: 436.1618 - nasa_loss: 1227.8094 - val_loss: 643.4520 - val_mse: 405.0039 - val_nasa_loss: 1345.4091\n",
            "Epoch 10/50\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 605.0842 - mse: 433.3531 - nasa_loss: 1337.4994 - val_loss: 596.4056 - val_mse: 483.2034 - val_nasa_loss: 1253.5459\n",
            "Epoch 11/50\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 574.3131 - mse: 407.5245 - nasa_loss: 1415.8285 - val_loss: 649.1984 - val_mse: 575.2986 - val_nasa_loss: 1048.1324\n",
            "Epoch 12/50\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 554.9949 - mse: 398.1183 - nasa_loss: 1499.0476 - val_loss: 600.8872 - val_mse: 521.3229 - val_nasa_loss: 1246.2758\n",
            "Epoch 13/50\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 539.0895 - mse: 386.4836 - nasa_loss: 1584.5703 - val_loss: 600.7941 - val_mse: 349.9176 - val_nasa_loss: 1609.3712\n",
            "Epoch 14/50\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 583.5084 - mse: 403.5271 - nasa_loss: 1635.3263 - val_loss: 600.7508 - val_mse: 333.1414 - val_nasa_loss: 2052.7952\n",
            "Epoch 15/50\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 563.4945 - mse: 395.9963 - nasa_loss: 1626.3408 - val_loss: 523.0911 - val_mse: 371.9106 - val_nasa_loss: 1660.8580\n",
            "Epoch 16/50\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 534.0162 - mse: 366.9395 - nasa_loss: 1670.3286 - val_loss: 571.9335 - val_mse: 372.3926 - val_nasa_loss: 1517.2583\n",
            "Epoch 17/50\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 542.8253 - mse: 375.2424 - nasa_loss: 1740.2644 - val_loss: 547.7549 - val_mse: 438.6579 - val_nasa_loss: 1326.7893\n",
            "Epoch 18/50\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 502.8758 - mse: 356.0574 - nasa_loss: 1710.2218 - val_loss: 578.4634 - val_mse: 526.2874 - val_nasa_loss: 1379.3618\n",
            "Epoch 19/50\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 524.9456 - mse: 369.7384 - nasa_loss: 1639.6127 - val_loss: 627.6977 - val_mse: 594.9749 - val_nasa_loss: 1427.3560\n",
            "Epoch 20/50\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 509.6869 - mse: 362.4988 - nasa_loss: 1814.2870 - val_loss: 559.2697 - val_mse: 457.0851 - val_nasa_loss: 1747.5299\n",
            "Epoch 21/50\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 515.5184 - mse: 359.4063 - nasa_loss: 1745.7792 - val_loss: 592.9864 - val_mse: 554.1141 - val_nasa_loss: 1311.7699\n",
            "Epoch 22/50\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 502.6684 - mse: 350.5621 - nasa_loss: 1775.5693 - val_loss: 539.0186 - val_mse: 476.6204 - val_nasa_loss: 1455.8641\n",
            "Epoch 23/50\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 507.8760 - mse: 359.4289 - nasa_loss: 1849.7239 - val_loss: 517.6262 - val_mse: 359.8506 - val_nasa_loss: 1859.9698\n",
            "Epoch 24/50\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 496.1512 - mse: 349.2797 - nasa_loss: 1867.0596 - val_loss: 512.1700 - val_mse: 420.5025 - val_nasa_loss: 1407.3215\n",
            "Epoch 25/50\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 493.8274 - mse: 351.0628 - nasa_loss: 1806.8875 - val_loss: 700.0939 - val_mse: 683.0151 - val_nasa_loss: 1135.3124\n",
            "Epoch 26/50\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 508.0652 - mse: 356.1433 - nasa_loss: 1868.1952 - val_loss: 699.0313 - val_mse: 667.9927 - val_nasa_loss: 1139.8893\n",
            "Epoch 27/50\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 533.1331 - mse: 383.0921 - nasa_loss: 1567.3560 - val_loss: 499.9942 - val_mse: 418.5965 - val_nasa_loss: 1691.3403\n",
            "Epoch 28/50\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 479.0597 - mse: 333.8347 - nasa_loss: 1993.3953 - val_loss: 523.4534 - val_mse: 430.7617 - val_nasa_loss: 1616.8179\n",
            "Epoch 29/50\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 491.4268 - mse: 349.7550 - nasa_loss: 1837.0636 - val_loss: 517.2161 - val_mse: 404.1974 - val_nasa_loss: 1529.7913\n",
            "Epoch 30/50\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 479.1884 - mse: 340.4390 - nasa_loss: 1821.8076 - val_loss: 537.8015 - val_mse: 380.7641 - val_nasa_loss: 2016.5560\n",
            "Epoch 31/50\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 508.0506 - mse: 357.5514 - nasa_loss: 1891.8470 - val_loss: 548.8908 - val_mse: 499.0022 - val_nasa_loss: 1625.4906\n",
            "Epoch 32/50\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 480.0469 - mse: 336.1560 - nasa_loss: 1849.6095 - val_loss: 585.0994 - val_mse: 553.6429 - val_nasa_loss: 1299.1921\n",
            "Epoch 33/50\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 500.1994 - mse: 358.3081 - nasa_loss: 1835.0442 - val_loss: 491.1949 - val_mse: 334.0269 - val_nasa_loss: 2022.3594\n",
            "Epoch 34/50\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 479.8631 - mse: 330.4117 - nasa_loss: 1934.3936 - val_loss: 536.9167 - val_mse: 481.5067 - val_nasa_loss: 1417.3550\n",
            "Epoch 35/50\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 468.9133 - mse: 332.7693 - nasa_loss: 1898.0745 - val_loss: 580.5790 - val_mse: 538.6497 - val_nasa_loss: 1251.1270\n",
            "Epoch 36/50\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 468.1565 - mse: 332.1663 - nasa_loss: 1776.8170 - val_loss: 492.7630 - val_mse: 405.5618 - val_nasa_loss: 1676.0881\n",
            "Epoch 37/50\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 476.3731 - mse: 329.0055 - nasa_loss: 1979.1517 - val_loss: 501.8329 - val_mse: 435.3381 - val_nasa_loss: 1621.6826\n",
            "Epoch 38/50\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 455.9742 - mse: 318.5153 - nasa_loss: 2088.6978 - val_loss: 607.6311 - val_mse: 576.0143 - val_nasa_loss: 1244.5786\n",
            "Epoch 39/50\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 459.8675 - mse: 326.4399 - nasa_loss: 1866.6350 - val_loss: 498.3392 - val_mse: 431.6685 - val_nasa_loss: 1514.4033\n",
            "Epoch 40/50\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 452.7586 - mse: 318.6926 - nasa_loss: 1950.5681 - val_loss: 550.3527 - val_mse: 499.6338 - val_nasa_loss: 1462.2352\n",
            "Epoch 41/50\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 471.4442 - mse: 328.2529 - nasa_loss: 1804.2811 - val_loss: 518.0566 - val_mse: 440.7034 - val_nasa_loss: 1470.5688\n",
            "Epoch 42/50\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 453.5811 - mse: 321.2221 - nasa_loss: 1891.0411 - val_loss: 485.9126 - val_mse: 382.0327 - val_nasa_loss: 2197.9976\n",
            "Epoch 43/50\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 471.4275 - mse: 333.7230 - nasa_loss: 1782.3965 - val_loss: 498.6124 - val_mse: 437.9405 - val_nasa_loss: 1712.8704\n",
            "Epoch 44/50\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 472.6854 - mse: 335.3535 - nasa_loss: 1850.2094 - val_loss: 493.1418 - val_mse: 362.6598 - val_nasa_loss: 1631.3364\n",
            "Epoch 45/50\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 458.6671 - mse: 317.8372 - nasa_loss: 1918.9336 - val_loss: 496.3388 - val_mse: 435.5327 - val_nasa_loss: 1757.3776\n",
            "Epoch 46/50\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 455.0013 - mse: 322.7408 - nasa_loss: 1964.0353 - val_loss: 478.9002 - val_mse: 395.6016 - val_nasa_loss: 1641.8374\n",
            "Epoch 47/50\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 444.9274 - mse: 313.1589 - nasa_loss: 1972.3793 - val_loss: 498.2079 - val_mse: 424.4236 - val_nasa_loss: 1558.3104\n",
            "Epoch 48/50\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 448.6368 - mse: 319.4320 - nasa_loss: 1993.5013 - val_loss: 500.2820 - val_mse: 403.9351 - val_nasa_loss: 1585.2349\n",
            "Epoch 49/50\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 453.3563 - mse: 319.9444 - nasa_loss: 1785.0151 - val_loss: 478.9169 - val_mse: 346.6688 - val_nasa_loss: 2279.4067\n",
            "Epoch 50/50\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 433.6543 - mse: 300.7049 - nasa_loss: 2022.7039 - val_loss: 483.4226 - val_mse: 361.1639 - val_nasa_loss: 2088.9146\n",
            "Val asymm loss: 483.4226\n",
            "Val NASA loss : 2088.9146\n",
            "Val mse loss : 361.1639\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Defining Test Data"
      ],
      "metadata": {
        "id": "ud7h0_UeWom9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_test_data (rul_df, test_df, sequence_length = 30) :\n",
        "  engine_id = test_df['unit_nr'].unique()\n",
        "  X_test = []\n",
        "  Y_test = []\n",
        "\n",
        "  for engine in engine_id :\n",
        "    engine_data = test_df[test_df['unit_nr'] == engine]\n",
        "    if len(engine_data) >= sequence_length :\n",
        "      window = engine_data[feature_cols].values[-sequence_length :]\n",
        "      current_engine_rul = rul_df.iloc[engine - 1]['RUL']\n",
        "      Y_test.append(current_engine_rul)\n",
        "      X_test.append(window)\n",
        "    else :\n",
        "      print('ENOUGH DATA NOT AVAILABLE')\n",
        "\n",
        "\n",
        "  return np.array(X_test), np.array(Y_test)"
      ],
      "metadata": {
        "id": "bNKZayECMxtS"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequence_length = 30\n",
        "test_df = pd.read_csv('final_test_FD001.csv')\n",
        "rul_df = pd.read_csv('RUL_FD001.csv')\n",
        "X_test, Y_test = process_test_data(rul_df, test_df, sequence_length)\n",
        "print(f\"Final Test Input Shape: {X_test.shape}\")\n",
        "print(f\"Final Test Label Shape: {Y_test.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pTFGasDzQ3Jr",
        "outputId": "7e096309-dce7-4a22-b3ff-69794ff62f8e"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Test Input Shape: (100, 30, 14)\n",
            "Final Test Label Shape: (100,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing"
      ],
      "metadata": {
        "id": "_1eRSPhVWvE_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_test = model.predict(X_test)\n",
        "y_true = Y_test.flatten()\n",
        "y_pred = y_pred_test.flatten()\n",
        "test_mse = mean_squared_error(y_true, y_pred)\n",
        "test_NASA = NASA_loss(y_true, y_pred)\n",
        "print(f\"MSE Accuracy   : {test_mse:.2f}\")\n",
        "print(f\"NASA Safety    : {test_NASA:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "reWH8gvmVGR_",
        "outputId": "806c4508-1dd1-492f-cd4c-0609bf45ca15"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
            "MSE Accuracy   : 1336.71\n",
            "NASA Safety    : 38.64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Final Plots for Testing Data :"
      ],
      "metadata": {
        "id": "RNtj_GseWzzW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot 1: Prediction Alignment\n",
        "plt.figure(figsize=(12, 5))\n",
        "sorted_indices = np.argsort(y_true)\n",
        "plt.plot(y_true[sorted_indices], color='black', linewidth=2, label='Actual RUL')\n",
        "plt.scatter(np.arange(len(y_pred)), y_pred[sorted_indices], color='red', s=15, alpha=0.5, label='Predicted RUL')\n",
        "plt.title(f'Final Test Predictions\\nMSE: {test_mse:.0f} | NASA Score: {test_NASA:.0f}')\n",
        "plt.xlabel('Engine # (Sorted by Life)')\n",
        "plt.ylabel('RUL')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.show()\n",
        "\n",
        "# Plot 2: Safety Histogram\n",
        "errors = y_pred - y_true\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.hist(errors, bins=40, color='green', alpha=0.7, edgecolor='black')\n",
        "plt.axvline(x=0, color='black', linestyle='--', linewidth=2, label='Zero Error')\n",
        "plt.axvspan(0, 100, color='red', alpha=0.1, label='Dangerous Zone (Late)')\n",
        "plt.title('Final Safety Check: Error Distribution')\n",
        "plt.xlabel('Error (Predicted - True)')\n",
        "plt.ylabel('Count')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 978
        },
        "id": "nO5NI_cCWZIE",
        "outputId": "e9231035-f7b1-488c-9949-ae5f50df1328"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}